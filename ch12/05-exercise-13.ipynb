{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Train a model using a custom training loop to tackle the Fashion MNIST dataset (see Chapter 10):\n",
    "a. Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch.\n",
    "\n",
    "b. Try using a different optimizer with a different learning rate for the upper layers and the lower layers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T19:56:22.248681Z",
     "start_time": "2023-06-22T19:56:19.094389Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T20:05:41.782679Z",
     "start_time": "2023-06-22T20:05:41.779413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train_full, x_test = x_train_full / 256.0, x_test / 256.0\n",
    "x_train, x_valid = x_train_full[:-5000], x_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T20:10:26.922285Z",
     "start_time": "2023-06-22T20:10:26.603185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(30, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T18:30:13.061229Z",
     "start_time": "2023-06-23T18:30:12.874262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.legacy.Nadam(learning_rate=0.0005),\n",
    "    metrics=[tf.keras.metrics.sparse_categorical_crossentropy]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T18:30:17.980745Z",
     "start_time": "2023-06-23T18:30:17.971753Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.5400 - sparse_categorical_crossentropy: 0.5400 - val_loss: 0.4006 - val_sparse_categorical_crossentropy: 0.4006\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3920 - sparse_categorical_crossentropy: 0.3920 - val_loss: 0.3540 - val_sparse_categorical_crossentropy: 0.3540\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.3545 - sparse_categorical_crossentropy: 0.3545 - val_loss: 0.3368 - val_sparse_categorical_crossentropy: 0.3368\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3290 - sparse_categorical_crossentropy: 0.3290 - val_loss: 0.2999 - val_sparse_categorical_crossentropy: 0.2999\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3098 - sparse_categorical_crossentropy: 0.3098 - val_loss: 0.2890 - val_sparse_categorical_crossentropy: 0.2890\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2953 - sparse_categorical_crossentropy: 0.2953 - val_loss: 0.2943 - val_sparse_categorical_crossentropy: 0.2943\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2844 - sparse_categorical_crossentropy: 0.2844 - val_loss: 0.2852 - val_sparse_categorical_crossentropy: 0.2852\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2722 - sparse_categorical_crossentropy: 0.2722 - val_loss: 0.2645 - val_sparse_categorical_crossentropy: 0.2645\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2632 - sparse_categorical_crossentropy: 0.2632 - val_loss: 0.2637 - val_sparse_categorical_crossentropy: 0.2637\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2557 - sparse_categorical_crossentropy: 0.2557 - val_loss: 0.2390 - val_sparse_categorical_crossentropy: 0.2390\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2476 - sparse_categorical_crossentropy: 0.2476 - val_loss: 0.2285 - val_sparse_categorical_crossentropy: 0.2285\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2398 - sparse_categorical_crossentropy: 0.2398 - val_loss: 0.2269 - val_sparse_categorical_crossentropy: 0.2269\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2328 - sparse_categorical_crossentropy: 0.2328 - val_loss: 0.2347 - val_sparse_categorical_crossentropy: 0.2347\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2266 - sparse_categorical_crossentropy: 0.2266 - val_loss: 0.2125 - val_sparse_categorical_crossentropy: 0.2125\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2212 - sparse_categorical_crossentropy: 0.2212 - val_loss: 0.2046 - val_sparse_categorical_crossentropy: 0.2046\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2144 - sparse_categorical_crossentropy: 0.2144 - val_loss: 0.1904 - val_sparse_categorical_crossentropy: 0.1904\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2081 - sparse_categorical_crossentropy: 0.2081 - val_loss: 0.2091 - val_sparse_categorical_crossentropy: 0.2091\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2046 - sparse_categorical_crossentropy: 0.2046 - val_loss: 0.1949 - val_sparse_categorical_crossentropy: 0.1949\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1995 - sparse_categorical_crossentropy: 0.1995 - val_loss: 0.2133 - val_sparse_categorical_crossentropy: 0.2133\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1936 - sparse_categorical_crossentropy: 0.1936 - val_loss: 0.1876 - val_sparse_categorical_crossentropy: 0.1876\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x29c1f9ed0>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_train, y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T18:37:56.184109Z",
     "start_time": "2023-06-23T18:30:20.736781Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T20:00:37.683559Z",
     "start_time": "2023-06-23T20:00:37.679268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "def print_status_bar(step, total, loss, metrics=None):\n",
    "    metrics = ' - '.join([f'{m.name}: {m.result():.4f}' for m in [loss] + (metrics or [])])\n",
    "    end = '' if step < total else '\\n'\n",
    "    print(f'\\r{step}/{total} - ' + metrics, end=end)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T20:00:42.410588Z",
     "start_time": "2023-06-23T20:00:42.407929Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "n_steps = x_train.shape[0] // 32\n",
    "n_epochs = 10\n",
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "optimizer = tf.keras.optimizers.legacy.Nadam(learning_rate=0.0005)\n",
    "mean_loss = tf.keras.metrics.Mean(name='mean_loss')\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T20:03:30.397568Z",
     "start_time": "2023-06-23T20:03:30.369117Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - mean_loss: 0.1820 - sparse_categorical_accuracy: 0.9324\n",
      "Epoch 2/10\n",
      "1875/1875 - mean_loss: 0.1774 - sparse_categorical_accuracy: 0.9350\n",
      "Epoch 3/10\n",
      "1875/1875 - mean_loss: 0.1706 - sparse_categorical_accuracy: 0.9359\n",
      "Epoch 4/10\n",
      "1875/1875 - mean_loss: 0.1702 - sparse_categorical_accuracy: 0.9376\n",
      "Epoch 5/10\n",
      "1875/1875 - mean_loss: 0.1675 - sparse_categorical_accuracy: 0.9395\n",
      "Epoch 6/10\n",
      "1875/1875 - mean_loss: 0.1631 - sparse_categorical_accuracy: 0.9397\n",
      "Epoch 7/10\n",
      "1875/1875 - mean_loss: 0.1576 - sparse_categorical_accuracy: 0.9420\n",
      "Epoch 8/10\n",
      "1875/1875 - mean_loss: 0.1557 - sparse_categorical_accuracy: 0.9432\n",
      "Epoch 9/10\n",
      "1875/1875 - mean_loss: 0.1541 - sparse_categorical_accuracy: 0.9423\n",
      "Epoch 10/10\n",
      "1875/1875 - mean_loss: 0.1532 - sparse_categorical_accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f'Epoch {epoch}/{n_epochs}')\n",
    "    for step in range(1, n_steps + 1):\n",
    "        x_batch, y_batch = random_batch(x_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            # We are using add_n since model.losses returns a scalar tensor per loss\n",
    "            # (in this case the model has regularization loss per layer)\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        # Perform a gradient descent step\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        # Add weight constraints\n",
    "        for variable in model.trainable_variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        # Calculate the loss and metrics for the epoch\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "\n",
    "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
    "\n",
    "    # Reset the metrics every epoch\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_state()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T20:10:16.212496Z",
     "start_time": "2023-06-23T20:03:31.589666Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
