{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. What are the advantages of a CNN over a fully connected DNN for image classification?\n",
    "> Number of parameters is much smaller, as the spatial dimensions are stateless and do not \"cost\" parameters\n",
    "\n",
    "From the book:\n",
    "> When a kernel learns how to detect a pattern, it can detect it anywhere in the image. This is not the case for DNN.\n",
    "> A DNN has no knowledge of pixel locality. With CNN, this is taken into account."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of 2, and \"same\" padding. The lowest layer outputs 100 feature maps, the middle one outputs 200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels:\n",
    "a. What is the total number of parameters in the CNN?\n",
    "> Lowest layer has (3 x 3 x 3 + 1 bias) x 100 = 2800 parameters\n",
    "> Middle layer has (3 x 3 x 100 + 1 bias) x 200 = 180,200 parameters\n",
    "> Top layer has (3 x 3 x 200 + 1 bias) x 400 = 720,400 parameters\n",
    "> Total parameters is 903,400\n",
    "\n",
    "b. If we are using 32-bit floats, at least how much RAM will this network require when making a prediction for a single instance?\n",
    "> Parameters = 4 bytes x 903,400 = 3.6M\n",
    "> First layer = 4 bytes x 100 x 150 x 100 = 6M\n",
    "> Second layer = 4 bytes x 50 x 75 x 200 = 3M\n",
    "> Third layer = 4 bytes x 25 x 38 x 400 = 1.5M\n",
    "> When making inference, we just do a forward pass. So we can release the memory of layer X as soon as layer X+1 was computed. So if everything is optimized, the maximum memory needed is first layer + second layer + parameters = 6M+3M+3.6M=12.6M.\n",
    "\n",
    "c. What about when training on a mini-batch of 50 images?\n",
    "> When training, we cannot release memory as we need it for the backprop.\n",
    "> So total of layers = 6+3+1.5=10.5M\n",
    "> Input = 4 bytes x 200 x 300 x 3 = 720K\n",
    "> So this is (10.5M+720K) x 50 = 561MB\n",
    "> Plus parameters of 3.6M => 564.6M. This ignores RAM needed for gradient calculations, so is optimistic."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. If your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?\n",
    "> Reduce batch size\n",
    "> Reduce dimensionality by increasing strides (me: or introducing max pooling layers)\n",
    "> Reduce number of layers (me: or change their type to one with less params, e.g. separable convolution layers)\n",
    "> Change to float 16 instead of float 32\n",
    "> Distribute CNN across devices\n",
    "\n",
    "I said but it was not in the book:\n",
    "> Reduce number of feature maps\n",
    "> Reduce kernel size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?\n",
    "> It is stateless and has no parameters, so it is an effective way to reduce the memory and computation requirements across the spatial dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. When would you want to add a local response normalization layer?\n",
    "> To increase the specialization of feature maps\n",
    ">\n",
    "Book added:\n",
    "> It is typically used in the lower layers to have a larger pool of low-level features that the upper layers can build upon."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Can you name the main innovations in AlexNet, as compared to LeNet-5? What about the main innovations in GoogLeNet, ResNet, SENet, Xception, and EfficientNet?\n",
    "> AlexNet introduced the LRN\n",
    "> GoogLeNet introduced the Inception Module\n",
    "> ResNet introduced the Residual Unit\n",
    "> SENet improved GoogLeNet and ResNet by introducing the Squeeze and Excitation layer\n",
    "> Xception introduced the separable convolution layers\n",
    "> EfficientNet allowed to find how to effectively scale the network given increase in computation capacity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. What is a fully convolutional network? How can you convert a dense layer into a convolutional layer?\n",
    "> Instead of a dense layer, we add a convolution layer that behaves similarly. The advantage is that it is insensitive to the spatial dimension, and can be used to slide a CNN on an image, which can be useful for object detection applications.\n",
    "> To convert a dense layer to an FCN, apply a filter the size of the spatial output of the previous layer with padding=valid, with the same number of feature maps as the dense layer's units."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8. What is the main technical difficulty of semantic segmentation?\n",
    "> As we go through a CNN, typically the resolution gets reduced due to max pooling layers and strides. So we have to find a way to increase the resolution back, using Transposed Convolution Layers for upsampling."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
