{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN, and a vector-to-sequence RNN?\n",
    "\n",
    "> Sequence to sequence:\n",
    "> - Generating text\n",
    "> - Predicting some metric (e.g. temperature, sales, etc.) multiple days into the future\n",
    "> Sequence to vector:\n",
    "> - Encoding text into some representation, e.g. for translation\n",
    "> Vector to sequence:\n",
    "> - Decoding from some representation, e.g. output of translation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. How many dimensions must the inputs of an RNN layer have? What does each dimension represent? What about its outputs?\n",
    "> Input: [batch size, sequence, features]\n",
    "> Output with return_sequences=False: [batch size, units]\n",
    "> Output with return_sequences=True: [batch size, sequence, units]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. If you want to build a deep sequence-to-sequence RNN, which RNN layers should have return_sequences=True? What about a sequence-to-vector RNN?\n",
    "> Seq2Seq: all RNN layers\n",
    "> Seq2Vec: all RNN layers except the last one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Suppose you have a daily univariate time series, and you want to forecast the next seven days. Which RNN architecture should you use?\n",
    "> Input: [batch size, sequence length, 1]\n",
    "> Output: [batch size, sequence length, 7] and ignore in inference all but the first output\n",
    "> Architecture: sequence-to-sequence architecture to make sure the gradients flow well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. What are the main difficulties when training RNNs? How can you handle them?\n",
    "> Unstable gradients. A few ways to handle these:\n",
    "> - Kernel initialization\n",
    "> - Saturating activation functions (tanh)\n",
    "> - Sequence-to-sequence during training to ensure loss is accounted for early time steps\n",
    "> - Layer normalization (not batch normalization)\n",
    "> - Dropouts after each time step"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Can you sketch the LSTM cell's architecture?\n",
    "> Yes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Why would you want to use 1D convolutional layers in an RNN?\n",
    "> It can shorten the input, which is important since cells have very limited memory (up to 100 steps or so - even LSTM and GRU)\n",
    "> It can detect patterns on a very long sequence by using an architecture like WaveNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8. Which neural network architecture could you use to classify videos?\n",
    "> Sequence of images...\n",
    "> Combine RNN and CNN - First CNN to output some representations of each image and then RNN and finally a dense layer per class"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
