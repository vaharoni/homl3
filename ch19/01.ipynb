{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some setup (don't run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/tensorflow-serving-apt\"\n",
    "src = \"stable tensorflow-model-server tensorflow-model-server-universal\"\n",
    "!echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n",
    "!curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n",
    "!apt update -q && apt-get install -y tensorflow-model-server\n",
    "%pip install -q -U tensorflow-serving-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# model_base_path must have a folder structure with versions underneath. \n",
    "# E.g. `data/01`, `data/02`. Anything else won't work.\n",
    "tensorflow_model_server \\\n",
    "     --port=8500 \\\n",
    "     --rest_api_port=8501 \\\n",
    "     --model_name=my-rl-model \\\n",
    "     --model_base_path=/home/amitaharoni/workspace/homl3/ch18/data/01-policy # >my_server.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorrt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For JSON\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# For gRPC\n",
    "import grpc\n",
    "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([0.0273956, -0.00611216, 0.03585979, 0.0197368])[tf.newaxis].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"signature_name\": \"serving_default\", \"instances\": [[0.027395600453019142, -0.006112160161137581, 0.035859789699316025, 0.019736800342798233]]}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# You can see the signatures by doing:\n",
    "# saved_model_cli show --dir ch18/data/01-policy/01\n",
    "# saved_model_cli show --dir ch18/data/01-policy/01 --tag_set serve\n",
    "# saved_model_cli show --dir ch18/data/01-policy/01 --tag_set serve --signature_def serving_default\n",
    "request_json = json.dumps({\n",
    "    'signature_name': 'serving_default',\n",
    "    'instances': x.tolist()\n",
    "})\n",
    "\n",
    "request_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_url = 'http://localhost:8501/v1/models/my-rl-model:predict'\n",
    "response = requests.post(server_url, data=request_json)\n",
    "response.raise_for_status()\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = np.array(response['predictions'])\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = PredictRequest()\n",
    "request.model_spec.name = 'my-rl-model'\n",
    "request.model_spec.signature_name = 'serving_default'\n",
    "request.inputs['dense_input'].CopyFrom(tf.make_tensor_proto(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = grpc.insecure_channel('localhost:8500')\n",
    "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "response = predict_service.Predict(request, timeout=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_spec {\n",
       "  name: \"my-rl-model\"\n",
       "  version {\n",
       "    value: 1\n",
       "  }\n",
       "  signature_name: \"serving_default\"\n",
       "}\n",
       "outputs {\n",
       "  key: \"dense_1\"\n",
       "  value {\n",
       "    dtype: DT_FLOAT\n",
       "    tensor_shape {\n",
       "      dim {\n",
       "        size: 1\n",
       "      }\n",
       "      dim {\n",
       "        size: 1\n",
       "      }\n",
       "    }\n",
       "    float_val: 0.464128375\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46412838]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_protos = response.outputs['dense_1']\n",
    "y_proba = tf.make_ndarray(output_protos)\n",
    "y_proba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
