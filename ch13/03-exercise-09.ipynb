{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized Example protobuf with two features: the serialized image (use tf.io.serialize_tensor() to serialize each image), and the label (For large images, you could use tf.io.encode_jpeg() instead. This would save a lot of space, but it would lose a bit of image quality) Then use tf.data to create an efficient dataset for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T13:25:33.244309Z",
     "start_time": "2023-06-25T13:25:30.765929Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Splitting to files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_valid = x_train_full[:-5000], x_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "\n",
    "def to_protobuf(image, label):\n",
    "    image_bytes = tf.io.serialize_tensor(image).numpy()\n",
    "\n",
    "    image_feature = tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes]))\n",
    "    label_feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(\n",
    "        feature={\n",
    "            'image': image_feature,\n",
    "            'label': label_feature\n",
    "        }\n",
    "    ))\n",
    "\n",
    "def dump_batch(batch, subfolder, id):\n",
    "    file_name = f'data/mnist/{subfolder}/{str(id).zfill(4)}.tfrecord'\n",
    "    with tf.io.TFRecordWriter(file_name) as f:\n",
    "        for index, item in enumerate(batch['image']):\n",
    "            protobuf = to_protobuf(item, batch['label'][index])\n",
    "            bytes = protobuf.SerializeToString()\n",
    "            f.write(bytes)\n",
    "\n",
    "def preprocess(x, y, subfolder):\n",
    "    ds = tf.data.Dataset.from_tensor_slices({\n",
    "        'image': x,\n",
    "        'label': y\n",
    "    }).shuffle(buffer_size=10000).batch(100)\n",
    "    for id, batch in enumerate(ds):\n",
    "        dump_batch(batch, subfolder, id)\n",
    "\n",
    "# preprocess(x_test, y_test, 'test')\n",
    "# preprocess(x_train, y_train, 'train')\n",
    "# preprocess(x_valid, y_valid, 'valid')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T13:05:16.891959Z",
     "start_time": "2023-06-25T13:05:15.879161Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "feature_descriptions = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def parse(example_proto):\n",
    "    example = tf.io.parse_single_example(example_proto, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example['image'], out_type=tf.uint8)\n",
    "    image = tf.reshape(image, [28, 28])\n",
    "    label = example['label']\n",
    "    return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T13:32:12.879878Z",
     "start_time": "2023-06-25T13:32:12.875264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "training_files = tf.data.Dataset.list_files('data/mnist/train/*.tfrecord')\n",
    "training = tf.data.TFRecordDataset(training_files, num_parallel_reads=5).shuffle(10000).map(parse, num_parallel_calls=5).batch(batch_size).prefetch(1)\n",
    "\n",
    "valid_files = tf.data.Dataset.list_files('data/mnist/valid/*.tfrecord')\n",
    "valid = tf.data.TFRecordDataset(valid_files, num_parallel_reads=5).map(parse, num_parallel_calls=5).batch(batch_size).prefetch(1)\n",
    "\n",
    "test_files = tf.data.Dataset.list_files('data/mnist/test/*.tfrecord')\n",
    "test = tf.data.TFRecordDataset(test_files, num_parallel_reads=5).map(parse, num_parallel_calls=5).batch(batch_size).prefetch(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T13:36:43.105848Z",
     "start_time": "2023-06-25T13:36:43.043919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for x in training.take(1):\n",
    "    print(x[0].shape)\n",
    "    print(x[1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T13:40:29.857420Z",
     "start_time": "2023-06-25T13:40:29.795597Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1719/Unknown - 22s 11ms/step - loss: 0.3595 - sparse_categorical_accuracy: 0.8955INFO:tensorflow:Assets written to: data/mnist/checkpoints/assets\n",
      "1719/1719 [==============================] - 24s 12ms/step - loss: 0.3595 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.1522 - val_sparse_categorical_accuracy: 0.9584\n",
      "Epoch 2/10\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 0.1767 - sparse_categorical_accuracy: 0.9480INFO:tensorflow:Assets written to: data/mnist/checkpoints/assets\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.1768 - sparse_categorical_accuracy: 0.9480 - val_loss: 0.1186 - val_sparse_categorical_accuracy: 0.9652\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 0.1387 - sparse_categorical_accuracy: 0.9582INFO:tensorflow:Assets written to: data/mnist/checkpoints/assets\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.1387 - sparse_categorical_accuracy: 0.9582 - val_loss: 0.1120 - val_sparse_categorical_accuracy: 0.9666\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.1171 - sparse_categorical_accuracy: 0.9651 - val_loss: 0.1150 - val_sparse_categorical_accuracy: 0.9660\n",
      "Epoch 5/10\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 0.1035 - sparse_categorical_accuracy: 0.9677INFO:tensorflow:Assets written to: data/mnist/checkpoints/assets\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.1035 - sparse_categorical_accuracy: 0.9678 - val_loss: 0.1038 - val_sparse_categorical_accuracy: 0.9708\n",
      "Epoch 6/10\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.9715INFO:tensorflow:Assets written to: data/mnist/checkpoints/assets\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.0917 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1003 - val_sparse_categorical_accuracy: 0.9684\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.0839 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9688\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.0776 - sparse_categorical_accuracy: 0.9755 - val_loss: 0.1006 - val_sparse_categorical_accuracy: 0.9722\n",
      "Epoch 9/10\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 0.0701 - sparse_categorical_accuracy: 0.9779INFO:tensorflow:Assets written to: data/mnist/checkpoints/assets\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9726\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.0664 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.1062 - val_sparse_categorical_accuracy: 0.9702\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Rescaling(scale=1/255),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(30, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(30, activation='relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.legacy.Nadam(),\n",
    "    metrics=[tf.keras.metrics.sparse_categorical_accuracy],\n",
    ")\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard('data/mnist/tensorboard')\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('data/mnist/checkpoints', save_best_only=True)\n",
    "\n",
    "hist = model.fit(\n",
    "    training,\n",
    "    epochs=10,\n",
    "    validation_data=valid,\n",
    "    callbacks=[tensorboard_cb, checkpoint_cb]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T13:52:44.647208Z",
     "start_time": "2023-06-25T13:49:26.973848Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1292 - sparse_categorical_accuracy: 0.9640\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.1292203962802887, 0.9640000462532043]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-25T13:53:00.683285Z",
     "start_time": "2023-06-25T13:52:59.184388Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
