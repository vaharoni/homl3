{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an encoder–decoder model that can convert a date string from one format to another (e.g., from “April 22, 2019” to “2019-04-22”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import numpy as np\n",
    "import tensorrt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55883\n"
     ]
    }
   ],
   "source": [
    "def gen_dates():\n",
    "    res = []\n",
    "    for x in range(date(1900, 1, 1).toordinal(), date(2053, 1, 1).toordinal()):\n",
    "        d = date.fromordinal(x)\n",
    "        res.append((d.strftime('%B %d, %Y'), f'^{d.isoformat()}', f'{d.isoformat()}$'))\n",
    "    return res\n",
    "\n",
    "data = gen_dates()\n",
    "np.random.shuffle(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arr = data[:45000]\n",
    "validation_arr = data[45000:50000]\n",
    "test_arr = data[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(data, shuffle=False, batch_size=32):\n",
    "    encoder_inputs, decoder_inputs, labels = zip(*data)\n",
    "    encoder_inputs = tf.constant(encoder_inputs, dtype=tf.string)\n",
    "    decoder_inputs = tf.constant(decoder_inputs, dtype=tf.string)\n",
    "    labels = tf.constant(labels, dtype=tf.string)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((encoder_inputs, decoder_inputs), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(60000)\n",
    "    return ds.cache().batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = to_dataset(training_arr, shuffle=True)\n",
    "validation_ds = to_dataset(validation_arr)\n",
    "test_ds = to_dataset(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'February 04, 1959' b'September 19, 1915' b'March 07, 1943'\n",
      " b'September 14, 1922' b'November 17, 1976'], shape=(5,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'^1959-02-04' b'^1915-09-19' b'^1943-03-07' b'^1922-09-14'\n",
      " b'^1976-11-17'], shape=(5,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'1959-02-04$' b'1915-09-19$' b'1943-03-07$' b'1922-09-14$'\n",
      " b'1976-11-17$'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for (enc_in, dec_in), labels in validation_ds.take(1):\n",
    "    print(enc_in[:5])\n",
    "    print(dec_in[:5])\n",
    "    print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18, shape=(), dtype=int32) 38\n",
      "['', '[UNK]', '1', '0', '-', '2', '9', ' ', '3', '4', '5', '^', ',', '$', '8', '7', '6', 'e', 'r', 'a', 'u', 'm', 'b', 'y', 'c', 't', 'o', 'j', 'n', 's', 'l', 'p', 'h', 'g', 'd', 'v', 'i', 'f']\n"
     ]
    }
   ],
   "source": [
    "enc_in, dec_in, labels = zip(*data)\n",
    "all_strings = enc_in + dec_in + labels\n",
    "max_tokens = tf.reduce_max(tf.strings.length(all_strings))\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(standardize='lower', split='character')\n",
    "text_vec_layer.adapt(all_strings)\n",
    "\n",
    "vocab_size = text_vec_layer.vocabulary_size()\n",
    "print(max_tokens, vocab_size)\n",
    "print(text_vec_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16,), dtype=int64, numpy=array([26, 24, 25, 26, 22, 17, 18,  7,  3, 10, 12,  7,  2,  6, 14, 10])>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]\n",
    "text_vec_layer('October 05, 1985')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[27 19 28 20 19 18 23  7  3  2 12  7  2  6 16  5  0  0]\n",
      " [27 20 30 23  7  8  2 12  7  5  3  5  3  0  0  0  0  0]\n",
      " [29 17 31 25 17 21 22 17 18  7  3 16 12  7  2  6 14  9]], shape=(3, 18), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[11  2  6 16  5  4  3  2  4  3  2]\n",
      " [11  5  3  5  3  4  3 15  4  8  2]\n",
      " [11  2  6 14  9  4  3  6  4  3 16]], shape=(3, 11), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 2  6 16  5  4  3  2  4  3  2 13]\n",
      " [ 5  3  5  3  4  3 15  4  8  2 13]\n",
      " [ 2  6 14  9  4  3  6  4  3 16 13]], shape=(3, 11), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def tokenize(inputs, labels):\n",
    "    enc_in, dec_in = inputs\n",
    "    return (text_vec_layer(enc_in), text_vec_layer(dec_in)), text_vec_layer(labels)\n",
    "\n",
    "training = training_ds.map(tokenize)\n",
    "validation = validation_ds.map(tokenize)\n",
    "test = test_ds.map(tokenize)\n",
    "\n",
    "for (enc_in, dec_in), labels in test.take(1):\n",
    "    print(enc_in[:3])\n",
    "    print(dec_in[:3])\n",
    "    print(labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_50 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_49 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_24 (Embedding)       (None, None, 30)     1140        ['input_49[0][0]',               \n",
      "                                                                  'input_50[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional_20 (Bidirectiona  [(None, None, 256),  122880     ['embedding_24[0][0]']           \n",
      " l)                              (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " tf.concat_14 (TFOpLambda)      (None, 256)          0           ['bidirectional_20[0][1]',       \n",
      "                                                                  'bidirectional_20[0][2]']       \n",
      "                                                                                                  \n",
      " gru_38 (GRU)                   (None, None, 256)    221184      ['embedding_24[1][0]',           \n",
      "                                                                  'tf.concat_14[0][0]']           \n",
      "                                                                                                  \n",
      " attention_14 (Attention)       (None, None, 256)    0           ['gru_38[0][0]',                 \n",
      "                                                                  'bidirectional_20[0][0]']       \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, None, 38)     9766        ['attention_14[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 354,970\n",
      "Trainable params: 354,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_tokens = tf.keras.Input(shape=[None], dtype=tf.int64)\n",
    "decoder_tokens = tf.keras.Input(shape=[None], dtype=tf.int64)\n",
    "\n",
    "# Already tokenized\n",
    "# encoder_tokens = text_vec_layer(encoder_input)\n",
    "# decoder_tokens = text_vec_layer(decoder_input)\n",
    "\n",
    "embeddings_layer = tf.keras.layers.Embedding(vocab_size, 30, mask_zero=True)\n",
    "encoder_embeddings = embeddings_layer(encoder_tokens)\n",
    "decoder_embeddings = embeddings_layer(decoder_tokens)\n",
    "\n",
    "encoder_layer = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, return_state=True)\n",
    ")\n",
    "encoder_output, *encoder_states = encoder_layer(encoder_embeddings)\n",
    "bidir_encoder_states = tf.concat(encoder_states, axis=-1)\n",
    "\n",
    "decoder_layer = tf.keras.layers.GRU(256, return_sequences=True)\n",
    "decoder_output = decoder_layer(decoder_embeddings, initial_state=bidir_encoder_states)\n",
    "\n",
    "attention_layer = tf.keras.layers.Attention()\n",
    "attention_output = attention_layer([decoder_output, encoder_output])\n",
    "\n",
    "dense_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "output = dense_layer(attention_output)\n",
    "\n",
    "model = tf.keras.Model(inputs=[encoder_tokens, decoder_tokens], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.5831 - sparse_categorical_accuracy: 0.7975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_80_layer_call_fn, gru_cell_80_layer_call_and_return_conditional_losses, gru_cell_78_layer_call_fn, gru_cell_78_layer_call_and_return_conditional_losses, gru_cell_79_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 71s 43ms/step - loss: 0.5831 - sparse_categorical_accuracy: 0.7975 - val_loss: 0.0621 - val_sparse_categorical_accuracy: 0.9833\n",
      "Epoch 2/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 0.0394 - sparse_categorical_accuracy: 0.9917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_80_layer_call_fn, gru_cell_80_layer_call_and_return_conditional_losses, gru_cell_78_layer_call_fn, gru_cell_78_layer_call_and_return_conditional_losses, gru_cell_79_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 57s 41ms/step - loss: 0.0394 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.0178 - val_sparse_categorical_accuracy: 0.9959\n",
      "Epoch 3/10\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 0.0243 - sparse_categorical_accuracy: 0.9947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_80_layer_call_fn, gru_cell_80_layer_call_and_return_conditional_losses, gru_cell_78_layer_call_fn, gru_cell_78_layer_call_and_return_conditional_losses, gru_cell_79_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 53s 38ms/step - loss: 0.0243 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9999\n",
      "Epoch 4/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 0.0015 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_80_layer_call_fn, gru_cell_80_layer_call_and_return_conditional_losses, gru_cell_78_layer_call_fn, gru_cell_78_layer_call_and_return_conditional_losses, gru_cell_79_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 56s 40ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.0721e-04 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 37s 26ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0012 - val_sparse_categorical_accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 39s 28ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9990 - val_loss: 7.0685e-04 - val_sparse_categorical_accuracy: 0.9999\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0021 - sparse_categorical_accuracy: 0.9996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_80_layer_call_fn, gru_cell_80_layer_call_and_return_conditional_losses, gru_cell_78_layer_call_fn, gru_cell_78_layer_call_and_return_conditional_losses, gru_cell_79_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 54s 39ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9996 - val_loss: 5.2578e-04 - val_sparse_categorical_accuracy: 0.9999\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 37s 27ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.0452 - val_sparse_categorical_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 36s 26ms/step - loss: 0.0013 - sparse_categorical_accuracy: 0.9998 - val_loss: 6.5427e-04 - val_sparse_categorical_accuracy: 0.9999\n",
      "Epoch 10/10\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.1766e-04 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_80_layer_call_fn, gru_cell_80_layer_call_and_return_conditional_losses, gru_cell_78_layer_call_fn, gru_cell_78_layer_call_and_return_conditional_losses, gru_cell_79_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/05-exrc-9/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 53s 38ms/step - loss: 1.1765e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7707e-05 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "folder = Path() / 'data' / '05-exrc-9' / 'checkpoints'\n",
    "checkpoints_cb = tf.keras.callbacks.ModelCheckpoint(folder, save_best_only=True)\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=3)\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Nadam(),\n",
    "    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    ")\n",
    "hist = model.fit(training, epochs=10, validation_data=validation, callbacks=[checkpoints_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 2s 12ms/step - loss: 4.6766e-05 - sparse_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.676641401601955e-05, 1.0]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j', 'a', 'n', 'u', 'a', 'r', 'y', ' ', '0', '1', ',', ' ', '1', '9', '6', '2', '', '']\n"
     ]
    }
   ],
   "source": [
    "for (enc_in, dec_in), label in test.take(1):\n",
    "    print([text_vec_layer.get_vocabulary()[c] for c in enc_in[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-17\n",
      "1910-05-01\n"
     ]
    }
   ],
   "source": [
    "def infer(date_input):\n",
    "    result = ''\n",
    "    encoder_input = text_vec_layer([date_input])\n",
    "    for _ in range(max_tokens):\n",
    "        decoder_input = text_vec_layer(['^' + result])\n",
    "        y_proba = model.predict([encoder_input, decoder_input], verbose=False)[0, -1]\n",
    "        token = y_proba.argmax()\n",
    "        char = text_vec_layer.get_vocabulary()[token]\n",
    "        if char == '$':\n",
    "            break\n",
    "        result += char\n",
    "    return result\n",
    "\n",
    "print(infer('December 17, 2025'))\n",
    "print(infer('May 01, 1910'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book's solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach of the book's solution is an interesting one. It sends the output of the encoder X times as input to the decoder (since the input sequence to the decoder is fixed length). This means it doesn't need to initialize the internal state (which is essentially a hack needed since the \"teacher forcing\" technique takes over the input). The book calls `tf.keras.layers.RepeatVector` to duplicate the output of the encoder as many times needed for the decoder's sequence.\n",
    "\n",
    "It's also worth noting that the embeddings of the encoder and decoder are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "# cannot use strftime()'s %B format since it depends on the locale\n",
    "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "def random_dates(n_dates):\n",
    "    min_date = date(1000, 1, 1).toordinal()\n",
    "    max_date = date(9999, 12, 31).toordinal()\n",
    "\n",
    "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "\n",
    "    x = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                    Target                   \n",
      "--------------------------------------------------\n",
      "September 20, 7075       7075-09-20               \n",
      "May 15, 8579             8579-05-15               \n",
      "January 11, 7103         7103-01-11               \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_dates = 3\n",
    "x_example, y_example = random_dates(n_dates)\n",
    "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
    "print(\"-\" * 50)\n",
    "for idx in range(n_dates):\n",
    "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
    "INPUT_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHARS = \"0123456789-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
    "    return [chars.index(c) for c in date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 23, 31, 34, 23, 28, 21, 23, 32, 0, 4, 2, 1, 0, 9, 2, 9, 7]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(x_example[0], INPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(y_example[0], OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
    "    X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
    "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
    "    return (X + 1).to_tensor() # using 0 as the padding token ID\n",
    "\n",
    "def create_dataset(n_dates):\n",
    "    x, y = random_dates(n_dates)\n",
    "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_train, Y_train = create_dataset(10000)\n",
    "X_valid, Y_valid = create_dataset(2000)\n",
    "X_test, Y_test = create_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 8,  1,  8,  6, 11,  1, 10, 11,  3,  1], dtype=int32)>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 10])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 12s 27ms/step - loss: 1.6836 - accuracy: 0.4029 - val_loss: 1.2299 - val_accuracy: 0.5555\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 1.1028 - accuracy: 0.6098 - val_loss: 0.9235 - val_accuracy: 0.6597\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7736 - accuracy: 0.7114 - val_loss: 0.6715 - val_accuracy: 0.7371\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.7501 - accuracy: 0.7228 - val_loss: 0.5698 - val_accuracy: 0.7765\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.4590 - accuracy: 0.8174 - val_loss: 0.3853 - val_accuracy: 0.8439\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.3166 - accuracy: 0.8780 - val_loss: 0.2770 - val_accuracy: 0.8959\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2052 - accuracy: 0.9337 - val_loss: 0.1549 - val_accuracy: 0.9578\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.1051 - accuracy: 0.9756 - val_loss: 0.0804 - val_accuracy: 0.9843\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.1458 - accuracy: 0.9692 - val_loss: 0.0643 - val_accuracy: 0.9890\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0413 - accuracy: 0.9946 - val_loss: 0.0325 - val_accuracy: 0.9955\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0239 - accuracy: 0.9980 - val_loss: 0.0218 - val_accuracy: 0.9977\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0157 - accuracy: 0.9991 - val_loss: 0.0146 - val_accuracy: 0.9991\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0108 - accuracy: 0.9996 - val_loss: 0.0104 - val_accuracy: 0.9995\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0076 - accuracy: 0.9998 - val_loss: 0.0077 - val_accuracy: 0.9997\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0055 - accuracy: 0.9999 - val_loss: 0.0058 - val_accuracy: 0.9998\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0044 - val_accuracy: 0.9998\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9999\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9999\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9998\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 32\n",
    "max_output_length = Y_train.shape[1]\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1,\n",
    "                           output_dim=embedding_size,\n",
    "                           input_shape=[None]),\n",
    "    tf.keras.layers.LSTM(128)\n",
    "])\n",
    "\n",
    "decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.RepeatVector(max_output_length),\n",
    "    decoder\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 13), dtype=int32, numpy=\n",
       "array([[17, 21, 38,  1,  3,  5,  2,  1,  5,  3,  5,  3,  0],\n",
       "       [16, 36, 28, 38,  1,  4,  7,  2,  1,  4, 10, 11, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
