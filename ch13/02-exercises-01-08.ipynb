{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. Why would you want to use the tf.data API?\n",
    "\n",
    "> Because it makes it easy to utilize the available resources on the machine when processing large amounts of data (GPU & multi threading)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. What are the benefits of splitting a large dataset into multiple files?\n",
    "\n",
    "> it makes it possible to shuffle large amounts of data (for training purposes) without fitting the entire dataset in memory first"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. During training, how can you tell that your input pipeline is the bottleneck? What can you do to fix it?\n",
    "\n",
    "> if the GPU does not have high utilization. One way to fix it is use prefetch on the tf.data.Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Can you save any binary data to a TFRecord file, or only serialized protocol buffers?\n",
    "\n",
    "> Yes, TFRecord can be used to save arbitrary binary data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Why would you go through the hassle of converting all your data to the Example protobuf format? Why not use your own protobuf definition?\n",
    "\n",
    "> First, it depends on the use of the model - ideally the input data format will match the production application's format. It is possible to use our own protobuf definition, but it requires the hassle of defining the protobuf and compiling them. Instead, tensorflow comes ready with protobufs like Example."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. When using TFRecords, when would you want to activate compression? Why not do it systematically?\n",
    "\n",
    "> If the data needs to be sent over the wire, it's typically better to compress it. But this means the receiving end will have to decompress it before it can be used, which takes computing cycles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Data can be preprocessed directly when writing the data files, or within the tf.data pipeline, or in preprocessing layers within your model. Can you list a few pros and cons of each option?\n",
    "\n",
    "> The main pro of writing data files is that the preprocessing is done once before training starts. In the pipeline itself it means that preprocessing needs to occur for each epoch.\n",
    "> The main con of not reusing the same preprocessing layers is that there can be mistakes when preprocessing the data in production in a way that is not fully aligned with the preprocessing applied during training.\n",
    "> The best of both worlds is to create preprocessing layers, apply them on the entire dataset first, and then include the same layers in the production model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8. Name a few common ways you can encode categorical integer features. What about text?\n",
    "\n",
    "> One-hot encoding for small number of categories\n",
    "> Embedding for a large number of categories\n",
    "> StringLookup for word-by-word encoding\n",
    "> TextVectorization to break sentences down to words, then using some embedding layer or TF-IDF approach.\n",
    "> Another option is the embed each word in a sentence, then take the mean of each vector multiplied by sqrt(n) where n is the number of words in the sentence. This yields the sentence embedding."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
