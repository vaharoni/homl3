{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorrt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_url = 'https://homl.info/shakespeare'\n",
    "filepath = tf.keras.utils.get_file('shakespeare.txt', shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization through TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(split='character', standardize='lower')\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "encoded = text_vec_layer([shakespeare_text])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1\n",
      "  0 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1\n",
      "  4  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24\n",
      " 17  0  7 22  1  4 24 26], shape=(80,), dtype=int64)\n",
      "39\n",
      "1115394\n"
     ]
    }
   ],
   "source": [
    "encoded -= 2 # drop 0 (pad) and 1 (unknown)\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2\n",
    "dataset_size = len(encoded)\n",
    "\n",
    "print(encoded[:80])\n",
    "print(n_tokens)\n",
    "print(dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateless RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "#     dataset = dataset.window(2, shift=1).flat_map(lambda window: window.batch(2, drop_remainder=True))\n",
    "#     dataset = dataset.window(length, shift=1).flat_map(lambda window: window.batch(length, drop_remainder=True))\n",
    "#     if shuffle:\n",
    "#         dataset = dataset.shuffle(10000, seed=seed)\n",
    "#     return dataset.map(lambda x: (x[:, 0], x[:, 1])).batch(batch_size)\n",
    "\n",
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    dataset = dataset.window(length + 1, shift=1, drop_remainder=True).flat_map(lambda window: window.batch(length + 1))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000, seed=seed)\n",
    "    return dataset.map(lambda x: (x[:-1], x[1:])).batch(batch_size).prefetch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  5]\n",
      " [ 5  8]\n",
      " [ 8  7]\n",
      " [ 7  2]\n",
      " [ 2  0]]\n"
     ]
    }
   ],
   "source": [
    "for x, y in to_dataset(encoded[:80], 5).take(1):\n",
    "    print(np.concatenate([x[0].numpy()[:, None], y[0].numpy()[:, None]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100\n",
    "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set = to_dataset(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  31244/Unknown - 473s 15ms/step - loss: 1.3058 - accuracy: 0.6095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 490s 16ms/step - loss: 1.3058 - accuracy: 0.6095 - val_loss: 1.8652 - val_accuracy: 0.4867\n",
      "Epoch 2/10\n",
      "31245/31247 [============================>.] - ETA: 0s - loss: 1.2473 - accuracy: 0.6196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 472s 15ms/step - loss: 1.2473 - accuracy: 0.6196 - val_loss: 1.7871 - val_accuracy: 0.5058\n",
      "Epoch 3/10\n",
      "31246/31247 [============================>.] - ETA: 0s - loss: 1.2542 - accuracy: 0.6143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 482s 15ms/step - loss: 1.2542 - accuracy: 0.6143 - val_loss: 1.7420 - val_accuracy: 0.5114\n",
      "Epoch 4/10\n",
      "31247/31247 [==============================] - ETA: 0s - loss: 1.2793 - accuracy: 0.6048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 473s 15ms/step - loss: 1.2793 - accuracy: 0.6048 - val_loss: 1.7147 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "31247/31247 [==============================] - ETA: 0s - loss: 1.2702 - accuracy: 0.6068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 477s 15ms/step - loss: 1.2702 - accuracy: 0.6068 - val_loss: 1.6841 - val_accuracy: 0.5166\n",
      "Epoch 6/10\n",
      "31244/31247 [============================>.] - ETA: 0s - loss: 1.2778 - accuracy: 0.6034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 475s 15ms/step - loss: 1.2778 - accuracy: 0.6034 - val_loss: 1.6861 - val_accuracy: 0.5189\n",
      "Epoch 7/10\n",
      "31247/31247 [==============================] - 471s 15ms/step - loss: 1.2859 - accuracy: 0.6004 - val_loss: 1.6804 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "31244/31247 [============================>.] - ETA: 0s - loss: 1.2899 - accuracy: 0.5986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 475s 15ms/step - loss: 1.2899 - accuracy: 0.5986 - val_loss: 1.6615 - val_accuracy: 0.5224\n",
      "Epoch 9/10\n",
      "31247/31247 [==============================] - ETA: 0s - loss: 1.2958 - accuracy: 0.5965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/01-vanilla-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 473s 15ms/step - loss: 1.2958 - accuracy: 0.5965 - val_loss: 1.6415 - val_accuracy: 0.5245\n",
      "Epoch 10/10\n",
      "31247/31247 [==============================] - 482s 15ms/step - loss: 1.2958 - accuracy: 0.5961 - val_loss: 1.6409 - val_accuracy: 0.5243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88ac8e4050>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "folder = Path() / 'data/01-vanilla-char-rnn'\n",
    "checkpoints_folder = folder / 'checkpoints'\n",
    "if checkpoints_folder.exists():\n",
    "    model.load_weights(checkpoints_folder)\n",
    "else: \n",
    "    checkpoints_cb = tf.keras.callbacks.ModelCheckpoint(checkpoints_folder, save_best_only=True, monitor='val_accuracy')\n",
    "    history = model.fit(\n",
    "        train_set, \n",
    "        epochs=10,\n",
    "        validation_data=valid_set,\n",
    "        callbacks=[checkpoints_cb]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda x: x - 2),  # no <PAD> or <UNK> tokens\n",
    "    model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape: (1, 17, 39) = (1, input tokens, output probabilities)\n",
    "y_proba = full_model.predict(['To be or not to b'], verbose=False)[0, -1]\n",
    "y_logits = tf.math.log(y_proba)\n",
    "tf.random.categorical([y_logits], 1)[0, 0]\n",
    "# output_token = tf.argmax(y_proba) + 2\n",
    "# text_vec_layer.get_vocabulary()[output_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input: str, length: int, temperature=1, top_k=None):\n",
    "    output = input\n",
    "    top_k = top_k if top_k else n_tokens\n",
    "    for _ in range(length):\n",
    "        y_proba = full_model.predict([output], verbose=False)[0, -1:]\n",
    "        y_proba_values_topk, y_proba_indices_topk = tf.math.top_k(y_proba, top_k)\n",
    "        y_logits = tf.math.log(y_proba_values_topk) / temperature\n",
    "        draw = tf.random.categorical(y_logits, num_samples=1)[0, 0]\n",
    "        # + 2 is specific to the use case of ignoring PAD and UNK tokens of text_vec_layer\n",
    "        output_token = y_proba_indices_topk[0, draw] + 2 \n",
    "        output += text_vec_layer.get_vocabulary()[output_token]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be or not to be so will withou't.\n",
      "thou art a great the\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "print(generate_text('To be or not to b', length=40, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6652992298681197 0.33470077013188027\n",
      "-0.4075183698058058 -1.0945183698058054\n"
     ]
    }
   ],
   "source": [
    "a = 1.5634\n",
    "b = 0.8764\n",
    "\n",
    "softmax_a = np.exp(a) / (np.exp(a) + np.exp(b))\n",
    "softmax_b = np.exp(b) / (np.exp(a) + np.exp(b))\n",
    "\n",
    "print(softmax_a, softmax_b)\n",
    "print(np.log(softmax_a), np.log(softmax_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset_for_stateful_rnn(sequence, length):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(length + 1)).batch(1)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8], shape=(20,), dtype=int64)\n",
      "tf.Tensor([[19  5  8  7  2]], shape=(1, 5), dtype=int64)\n",
      "tf.Tensor([[5 8 7 2 0]], shape=(1, 5), dtype=int64)\n",
      "tf.Tensor([[ 0 18  5  2  5]], shape=(1, 5), dtype=int64)\n",
      "tf.Tensor([[18  5  2  5 35]], shape=(1, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(encoded[:20])\n",
    "for x, y in to_dataset_for_stateful_rnn(encoded[:80], 5).take(2):\n",
    "    # print(x.shape, y.shape)\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100\n",
    "train_set_stateful = to_dataset_for_stateful_rnn(encoded[:1_000_000], length=length)\n",
    "valid_set_stateful = to_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set_stateful = to_dataset_for_stateful_rnn(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   9998/Unknown - 149s 15ms/step - loss: 1.8669 - accuracy: 0.4495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 157s 15ms/step - loss: 1.8668 - accuracy: 0.4496 - val_loss: 1.6881 - val_accuracy: 0.4960\n",
      "Epoch 2/10\n",
      " 9997/10000 [============================>.] - ETA: 0s - loss: 1.5574 - accuracy: 0.5300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 155s 16ms/step - loss: 1.5573 - accuracy: 0.5300 - val_loss: 1.5974 - val_accuracy: 0.5215\n",
      "Epoch 3/10\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 1.4798 - accuracy: 0.5500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 150s 15ms/step - loss: 1.4797 - accuracy: 0.5501 - val_loss: 1.5612 - val_accuracy: 0.5283\n",
      "Epoch 4/10\n",
      " 9998/10000 [============================>.] - ETA: 0s - loss: 1.4409 - accuracy: 0.5604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 154s 15ms/step - loss: 1.4408 - accuracy: 0.5604 - val_loss: 1.5431 - val_accuracy: 0.5331\n",
      "Epoch 5/10\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 1.4172 - accuracy: 0.5661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 145s 15ms/step - loss: 1.4171 - accuracy: 0.5662 - val_loss: 1.5328 - val_accuracy: 0.5364\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 1.4011 - accuracy: 0.5702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 145s 14ms/step - loss: 1.4011 - accuracy: 0.5702 - val_loss: 1.5234 - val_accuracy: 0.5397\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 1.3893 - accuracy: 0.5733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 148s 15ms/step - loss: 1.3893 - accuracy: 0.5733 - val_loss: 1.5168 - val_accuracy: 0.5419\n",
      "Epoch 8/10\n",
      " 9999/10000 [============================>.] - ETA: 0s - loss: 1.3801 - accuracy: 0.5754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/02-stateful-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 149s 15ms/step - loss: 1.3801 - accuracy: 0.5754 - val_loss: 1.5144 - val_accuracy: 0.5441\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 147s 15ms/step - loss: 1.3732 - accuracy: 0.5772 - val_loss: 1.5151 - val_accuracy: 0.5431\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 143s 14ms/step - loss: 1.3678 - accuracy: 0.5785 - val_loss: 1.5115 - val_accuracy: 0.5422\n"
     ]
    }
   ],
   "source": [
    "stateful_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16, batch_input_shape=[1, None]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation='softmax')\n",
    "])\n",
    "\n",
    "# We still need to reset the states every epoch\n",
    "class ResetStateCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.model.reset_states()\n",
    "\n",
    "stateful_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "folder = Path() / 'data/02-stateful-char-rnn'\n",
    "checkpoints_folder = folder / 'checkpoints'\n",
    "if checkpoints_folder.exists():\n",
    "    stateful_model.load_weights(checkpoints_folder)\n",
    "else: \n",
    "    checkpoints_cb = tf.keras.callbacks.ModelCheckpoint(checkpoints_folder, save_best_only=True, monitor='val_accuracy')\n",
    "    history = stateful_model.fit(\n",
    "        train_set_stateful, \n",
    "        epochs=10,\n",
    "        validation_data=valid_set_stateful,\n",
    "        callbacks=[checkpoints_cb, ResetStateCallback()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_stateful_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda x: x - 2),\n",
    "    stateful_model\n",
    "])\n",
    "\n",
    "def generate_stateful_text(input: str, length: int, temperature=1):\n",
    "    output = input\n",
    "    for _ in range(length):\n",
    "        y_proba = full_stateful_model.predict([output], verbose=False)[0, -1:]\n",
    "        y_logits = tf.math.log(y_proba) / temperature\n",
    "        output_token = tf.random.categorical(y_logits, num_samples=1)[0, 0] + 2\n",
    "        output += text_vec_layer.get_vocabulary()[output_token]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be or not to be\n",
      "him for you was a given will i will ca\n"
     ]
    }
   ],
   "source": [
    "print(generate_stateful_text('to be or not to b', 40, temperature=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb_reviews', 'huggingface:imdb', 'huggingface:imdb_urdu_reviews']"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in tfds.list_builders() if 'imdb' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) (32,)\n",
      "tf.Tensor(b\"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\", shape=(), dtype=string)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "---\n",
      "tf.Tensor(b\"A blackly comic tale of a down-trodden priest, Nazarin showcases the economy that Luis Bunuel was able to achieve in being able to tell a deeply humanist fable with a minimum of fuss. As an output from his Mexican era of film making, it was an invaluable talent to possess, with little money and extremely tight schedules. Nazarin, however, surpasses many of Bunuel's previous Mexican films in terms of the acting (Francisco Rabal is excellent), narrative and theme.<br /><br />The theme, interestingly, is something that was explored again in Viridiana, made three years later in Spain. It concerns the individual's struggle for humanity and altruism amongst a society that rejects any notion of virtue. Father Nazarin, however, is portrayed more sympathetically than Sister Viridiana. Whereas the latter seems to choose charity because she wishes to atone for her (perceived) sins, Nazarin's whole existence and reason for being seems to be to help others, whether they (or we) like it or not. The film's last scenes, in which he casts doubt on his behaviour and, in a split second, has to choose between the life he has been leading or the conventional life that is expected of a priest, are so emotional because they concern his moral integrity and we are never quite sure whether it remains intact or not.<br /><br />This is a remarkable film and I would urge anyone interested in classic cinema to seek it out. It is one of Bunuel's most moving films, and encapsulates many of his obsessions: frustrated desire, mad love, religious hypocrisy etc. In my view 'Nazarin' is second only to 'The Exterminating Angel', in terms of his Mexican movies, and is certainly near the top of the list of Bunuel's total filmic output.\", shape=(), dtype=string)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "---\n",
      "tf.Tensor(b'Scary Movie 1-4, Epic Movie, Date Movie, Meet the Spartans, Not another Teen Movie and Another Gay Movie. Making \"Superhero Movie\" the eleventh in a series that single handily ruined the parody genre. Now I\\'ll admit it I have a soft spot for classics such as Airplane and The Naked Gun but you know you\\'ve milked a franchise so bad when you can see the gags a mile off. In fact the only thing that might really temp you into going to see this disaster is the incredibly funny but massive sell-out Leslie Neilson.<br /><br />You can tell he needs the money, wither that or he intends to go down with the ship like a good Capitan would. In no way is he bringing down this genre but hell he\\'s not helping it. But if I feel sorry for anybody in this film its decent actor Drake Bell who is put through an immense amount of embarrassment. The people who are put through the largest amount of torture by far however is the audience forced to sit through 90 minutes of laughless bile no funnier than herpes.<br /><br />After spoofing disaster films in Airplane!, police shows in The Naked Gun, and Hollywood horrors in Scary Movie 3 and 4, producer David Zucker sets his satirical sights on the superhero genre with this anarchic comedy lampooning everything from Spider-Man to X-Men and Superman Returns.<br /><br />Shortly after being bitten by a genetically altered dragonfly, high-school outcast Rick Riker (Drake Bell) begins to experience a startling transformation. Now Rick\\'s skin is as strong as steel, and he possesses the strength of ten men. Determined to use his newfound powers to fight crime, Rick creates a special costume and assumes the identity of The Dragonfly -- a fearless crime fighter dedicated to keeping the streets safe for law-abiding citizens.<br /><br />But every superhero needs a nemesis, and after Lou Landers (Christopher McDonald) is caught in the middle of an experiment gone horribly awry, he develops the power to leech the life force out of anyone he meets and becomes the villainous Hourglass. Intent on achieving immortality, the Hourglass attempts to gather as much life force as possible as the noble Dragonfly sets out to take down his archenemy and realize his destiny as a true hero. Craig Mazin writes and directs this low-flying spoof.<br /><br />featuring Tracy Morgan, Pamela Anderson, Leslie Nielsen, Marion Ross, Jeffrey Tambor, and Regina Hall.<br /><br />Hell Superhero Movie may earn some merit in the fact that it\\'s a hell of a lot better than Meet the Spartans and Epic Movie. But with great responsibility comes one of the worst outings of 2008 to date. Laughless but a little less irritating than Meet the Spartans. And in the same sense much more forgettable than meet the Spartans. But maybe that\\'s a good reason. There are still some of us trying to scrape away the stain that was Meet the Spartans from our memory.<br /><br />My final verdict? Avoid, unless you\\'re one of thoses people who enjoy such car crash cinema. As bad as Date Movie and Scary Movie 2 but not quite as bad as Meet the Spartans or Epic Movie. Super Villain.', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "raw_train_set, raw_valid_set, raw_test_set = tfds.load(\n",
    "    name='imdb_reviews',\n",
    "    split=['train[:90%]', 'train[90%:]', 'test'],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "train_set = raw_test_set.shuffle(10000).batch(32).prefetch(1)\n",
    "valid_set = raw_valid_set.batch(32).prefetch(1)\n",
    "test_set = raw_test_set.batch(32).prefetch(1)\n",
    "\n",
    "for x, y in test_set.take(1):\n",
    "    print(x.shape, y.shape)\n",
    "    print(x[0])\n",
    "    print(y[0])\n",
    "    print('---')\n",
    "    print(x[1])\n",
    "    print(y[1])\n",
    "    print('---')\n",
    "    print(x[2])\n",
    "    print(y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(b\"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\", shape=(), dtype=string)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(b'Strictly a routine, by-the-numbers western (directed by genre-mainstay Andrew V. McLaglen, so is that any wonder?). Army colonel Brian Keith spars with smarmy bandit Dean Martin, who has just kidnapped the colonel\\'s wife (Honor Blackman, who never found her niche after playing Pussy Galore in \"Goldfinger\"). Fist-fights, shoot-outs, stagecoach robberies and Denver Pyle in a supporting role...in other words, absolutely nothing new or original. Talking in a low monotone throughout, Keith gets to dally with a prostitute (something of a shock after his run on TV\\'s \"Family Affair\"), but otherwise this low-rent material wastes Keith\\'s amiable talents. It\\'s also bad news for Dino, who doesn\\'t seem to notice or care. Hack direction, poor writing and several unfunny attempts at lowball humor. * from ****', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for (x1, x2), (y1, y2), (z1, z2) in tf.data.Dataset.zip((raw_train_set, raw_test_set, raw_valid_set)).take(1):\n",
    "    print(x1)\n",
    "    print(x2)\n",
    "    print(y1)\n",
    "    print(y2)\n",
    "    print(z1)\n",
    "    print(z2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
    "full_dataset = tf.data.Dataset.zip((raw_train_set, raw_valid_set, raw_test_set)).map(lambda a, b, c: tf.stack((a[0], b[0], c[0])))\n",
    "text_vec_layer.adapt(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'i']\n",
      "tf.Tensor(\n",
      "[[2 7 8]\n",
      " [2 7 0]], shape=(2, 3), dtype=int64)\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(text_vec_layer.get_vocabulary()[:10])\n",
    "print(text_vec_layer(['the is in', 'the is']))\n",
    "print(text_vec_layer.vocabulary_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive: without masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 82s 102ms/step - loss: 0.6933 - binary_accuracy: 0.5032 - val_loss: 0.6930 - val_binary_accuracy: 0.5036\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 59s 75ms/step - loss: 0.6928 - binary_accuracy: 0.5038 - val_loss: 0.6927 - val_binary_accuracy: 0.5020\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "imdb_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Embedding(input_dim=text_vec_layer.vocabulary_size(), output_dim=embed_size),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "imdb_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=tf.keras.metrics.binary_accuracy\n",
    ")\n",
    "history = imdb_model.fit(\n",
    "    train_set,\n",
    "    epochs=2,\n",
    "    validation_data=valid_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 736)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(100,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(100,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(100,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(100,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Why is there no learning? Due to lots of zero padding, long padded sequences have the GRU cell forget what the review is about \n",
    "for x, y in train_set.take(1):\n",
    "    tokenized = text_vec_layer(x)\n",
    "    print(tokenized.shape)\n",
    "    for row in range(5):\n",
    "        # Print last 100 tokens in the sequence\n",
    "        print(tokenized[row][-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With masking: mask_zero=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 82s 99ms/step - loss: 0.4522 - binary_accuracy: 0.7814 - val_loss: 0.3544 - val_binary_accuracy: 0.8440\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 64s 81ms/step - loss: 0.3119 - binary_accuracy: 0.8703 - val_loss: 0.3247 - val_binary_accuracy: 0.8700\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "masked_imdb_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=text_vec_layer.vocabulary_size(), \n",
    "        output_dim=embed_size,\n",
    "        mask_zero=True\n",
    "    ),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "masked_imdb_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=tf.keras.metrics.binary_accuracy\n",
    ")\n",
    "history = masked_imdb_model.fit(\n",
    "    train_set,\n",
    "    epochs=2,\n",
    "    validation_data=valid_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With masking: tf.layers.Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative approach with Masking layer\n",
    "# tf.​​reduce_any(tf.math.not_equal(X, 0), axis=-1)\n",
    "masked_imdb_model2 = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Masking(),\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=text_vec_layer.vocabulary_size(), \n",
    "        output_dim=embed_size,\n",
    "    ),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With masking: Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None)\n"
     ]
    }
   ],
   "source": [
    "# Strings are considered atomic values and their length is not part of the shape\n",
    "# So with batches, the shape of the input is (32,) \n",
    "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "# Returns (32, sequence length)\n",
    "token_ids = text_vec_layer(inputs)\n",
    "# Returns (32, sequence length), so there is no need to do tf.reduce_any(..., axis=-1)\n",
    "mask = tf.not_equal(token_ids, 0)\n",
    "Z = tf.keras.layers.Embedding(\n",
    "    input_dim=text_vec_layer.vocabulary_size(), \n",
    "    output_dim=embed_size,\n",
    ")(token_ids)\n",
    "Z = tf.keras.layers.GRU(128, dropout=0.2)(Z, mask=mask)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(Z)\n",
    "masked_imdb_model3 = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=ch16/data/03-masked-char-rnn\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 84s 97ms/step - loss: 0.4927 - binary_accuracy: 0.7529 - val_loss: 0.3808 - val_binary_accuracy: 0.8468\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 60s 77ms/step - loss: 0.3138 - binary_accuracy: 0.8674 - val_loss: 0.3151 - val_binary_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "masked_imdb_model3.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=tf.keras.metrics.binary_accuracy\n",
    ")\n",
    "history = masked_imdb_model3.fit(\n",
    "    train_set,\n",
    "    epochs=2,\n",
    "    validation_data=valid_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Ragged tensors instead of masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer_ragged = tf.keras.layers.TextVectorization(max_tokens=vocab_size, ragged=True)\n",
    "text_vec_layer_ragged.adapt(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'i']\n",
      "<tf.RaggedTensor [[2, 7, 8], [2, 7]]>\n"
     ]
    }
   ],
   "source": [
    "print(text_vec_layer_ragged.get_vocabulary()[:10])\n",
    "print(text_vec_layer_ragged(['the is in', 'the is']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=ch16/data/03-masked-char-rnn\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.4631 - accuracy: 0.7749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/03-masked-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/03-masked-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 79s 98ms/step - loss: 0.4631 - accuracy: 0.7749 - val_loss: 0.3891 - val_accuracy: 0.8332\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - ETA: 0s - loss: 0.3069 - accuracy: 0.8731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/03-masked-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/03-masked-char-rnn/checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 63s 81ms/step - loss: 0.3069 - accuracy: 0.8731 - val_loss: 0.3081 - val_accuracy: 0.8740\n"
     ]
    }
   ],
   "source": [
    "folder = Path() / 'data/03-masked-char-rnn'\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(folder / 'tensorboard')\n",
    "print(f'tensorboard --logdir=ch16/{folder}')\n",
    "\n",
    "checkpoints_cb = tf.keras.callbacks.ModelCheckpoint(folder / 'checkpoints')\n",
    "\n",
    "ragged_imdb_model = tf.keras.Sequential([\n",
    "    text_vec_layer_ragged,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=text_vec_layer.vocabulary_size(), \n",
    "        output_dim=embed_size,\n",
    "    ),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "ragged_imdb_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = ragged_imdb_model.fit(\n",
    "    train_set,\n",
    "    epochs=2,\n",
    "    validation_data=valid_set,\n",
    "    callbacks=[tensorboard_cb, checkpoints_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/03-masked-char-rnn/tensorboard/model.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/03-masked-char-rnn/tensorboard/model.ckpt/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(folder / 'tensorboard' / 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw_train_set, raw_valid_set, raw_test_set \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mload(\n\u001b[1;32m      2\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimdb_reviews\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     split\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain[:90\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtrain[90\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m:]\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      4\u001b[0m     as_supervised\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m train_set \u001b[39m=\u001b[39m raw_test_set\u001b[39m.\u001b[39mshuffle(\u001b[39m5000\u001b[39m)\u001b[39m.\u001b[39mbatch(\u001b[39m16\u001b[39m)\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      8\u001b[0m valid_set \u001b[39m=\u001b[39m raw_valid_set\u001b[39m.\u001b[39mbatch(\u001b[39m16\u001b[39m)\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/logging/__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[1;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/load.py:652\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    649\u001b[0m as_dataset_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mshuffle_files\u001b[39m\u001b[39m'\u001b[39m, shuffle_files)\n\u001b[1;32m    650\u001b[0m as_dataset_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mread_config\u001b[39m\u001b[39m'\u001b[39m, read_config)\n\u001b[0;32m--> 652\u001b[0m ds \u001b[39m=\u001b[39m dbuilder\u001b[39m.\u001b[39;49mas_dataset(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mas_dataset_kwargs)\n\u001b[1;32m    653\u001b[0m \u001b[39mif\u001b[39;00m with_info:\n\u001b[1;32m    654\u001b[0m   \u001b[39mreturn\u001b[39;00m ds, dbuilder\u001b[39m.\u001b[39minfo\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/logging/__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[1;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/dataset_builder.py:831\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[39m# Create a dataset for each of the given splits\u001b[39;00m\n\u001b[1;32m    823\u001b[0m build_single_dataset \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_single_dataset,\n\u001b[1;32m    825\u001b[0m     shuffle_files\u001b[39m=\u001b[39mshuffle_files,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    829\u001b[0m     as_supervised\u001b[39m=\u001b[39mas_supervised,\n\u001b[1;32m    830\u001b[0m )\n\u001b[0;32m--> 831\u001b[0m all_ds \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39;49mmap_structure(build_single_dataset, split)\n\u001b[1;32m    832\u001b[0m \u001b[39mreturn\u001b[39;00m all_ds\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tree/__init__.py:435\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[0;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;49;00m args \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(flatten, structures))])\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tree/__init__.py:435\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[0;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/dataset_builder.py:849\u001b[0m, in \u001b[0;36mDatasetBuilder._build_single_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[1;32m    846\u001b[0m   batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mtotal_num_examples \u001b[39mor\u001b[39;00m sys\u001b[39m.\u001b[39mmaxsize\n\u001b[1;32m    848\u001b[0m \u001b[39m# Build base dataset\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m ds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_as_dataset(\n\u001b[1;32m    850\u001b[0m     split\u001b[39m=\u001b[39;49msplit,\n\u001b[1;32m    851\u001b[0m     shuffle_files\u001b[39m=\u001b[39;49mshuffle_files,\n\u001b[1;32m    852\u001b[0m     decoders\u001b[39m=\u001b[39;49mdecoders,\n\u001b[1;32m    853\u001b[0m     read_config\u001b[39m=\u001b[39;49mread_config,\n\u001b[1;32m    854\u001b[0m )\n\u001b[1;32m    855\u001b[0m \u001b[39m# Auto-cache small datasets which are small enough to fit in memory.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_cache_ds(\n\u001b[1;32m    857\u001b[0m     split\u001b[39m=\u001b[39msplit, shuffle_files\u001b[39m=\u001b[39mshuffle_files, read_config\u001b[39m=\u001b[39mread_config\n\u001b[1;32m    858\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/dataset_builder.py:1302\u001b[0m, in \u001b[0;36mFileReaderBuilder._as_dataset\u001b[0;34m(self, split, decoders, read_config, shuffle_files)\u001b[0m\n\u001b[1;32m   1296\u001b[0m reader \u001b[39m=\u001b[39m reader_lib\u001b[39m.\u001b[39mReader(\n\u001b[1;32m   1297\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir,\n\u001b[1;32m   1298\u001b[0m     example_specs\u001b[39m=\u001b[39mexample_specs,\n\u001b[1;32m   1299\u001b[0m     file_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mfile_format,\n\u001b[1;32m   1300\u001b[0m )\n\u001b[1;32m   1301\u001b[0m decode_fn \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(features\u001b[39m.\u001b[39mdecode_example, decoders\u001b[39m=\u001b[39mdecoders)\n\u001b[0;32m-> 1302\u001b[0m \u001b[39mreturn\u001b[39;00m reader\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m   1303\u001b[0m     instructions\u001b[39m=\u001b[39;49msplit,\n\u001b[1;32m   1304\u001b[0m     split_infos\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49msplits\u001b[39m.\u001b[39;49mvalues(),\n\u001b[1;32m   1305\u001b[0m     decode_fn\u001b[39m=\u001b[39;49mdecode_fn,\n\u001b[1;32m   1306\u001b[0m     read_config\u001b[39m=\u001b[39;49mread_config,\n\u001b[1;32m   1307\u001b[0m     shuffle_files\u001b[39m=\u001b[39;49mshuffle_files,\n\u001b[1;32m   1308\u001b[0m     disable_shuffling\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49mdisable_shuffling,\n\u001b[1;32m   1309\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/reader.py:418\u001b[0m, in \u001b[0;36mReader.read\u001b[0;34m(self, instructions, split_infos, read_config, shuffle_files, disable_shuffling, decode_fn)\u001b[0m\n\u001b[1;32m    409\u001b[0m   file_instructions \u001b[39m=\u001b[39m splits_dict[instruction]\u001b[39m.\u001b[39mfile_instructions\n\u001b[1;32m    410\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_files(\n\u001b[1;32m    411\u001b[0m       file_instructions,\n\u001b[1;32m    412\u001b[0m       read_config\u001b[39m=\u001b[39mread_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m       decode_fn\u001b[39m=\u001b[39mdecode_fn,\n\u001b[1;32m    416\u001b[0m   )\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m tree_utils\u001b[39m.\u001b[39;49mmap_structure(_read_instruction_to_ds, instructions)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tree/__init__.py:435\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[0;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;49;00m args \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(flatten, structures))])\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tree/__init__.py:435\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[0;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/reader.py:410\u001b[0m, in \u001b[0;36mReader.read.<locals>._read_instruction_to_ds\u001b[0;34m(instruction)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_instruction_to_ds\u001b[39m(instruction):\n\u001b[1;32m    409\u001b[0m   file_instructions \u001b[39m=\u001b[39m splits_dict[instruction]\u001b[39m.\u001b[39mfile_instructions\n\u001b[0;32m--> 410\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_files(\n\u001b[1;32m    411\u001b[0m       file_instructions,\n\u001b[1;32m    412\u001b[0m       read_config\u001b[39m=\u001b[39;49mread_config,\n\u001b[1;32m    413\u001b[0m       shuffle_files\u001b[39m=\u001b[39;49mshuffle_files,\n\u001b[1;32m    414\u001b[0m       disable_shuffling\u001b[39m=\u001b[39;49mdisable_shuffling,\n\u001b[1;32m    415\u001b[0m       decode_fn\u001b[39m=\u001b[39;49mdecode_fn,\n\u001b[1;32m    416\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/reader.py:450\u001b[0m, in \u001b[0;36mReader.read_files\u001b[0;34m(self, file_instructions, read_config, shuffle_files, disable_shuffling, decode_fn)\u001b[0m\n\u001b[1;32m    447\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    449\u001b[0m \u001b[39m# Read serialized example (eventually with `tfds_id`)\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m ds \u001b[39m=\u001b[39m _read_files(\n\u001b[1;32m    451\u001b[0m     file_instructions\u001b[39m=\u001b[39;49mfile_instructions,\n\u001b[1;32m    452\u001b[0m     read_config\u001b[39m=\u001b[39;49mread_config,\n\u001b[1;32m    453\u001b[0m     shuffle_files\u001b[39m=\u001b[39;49mshuffle_files,\n\u001b[1;32m    454\u001b[0m     disable_shuffling\u001b[39m=\u001b[39;49mdisable_shuffling,\n\u001b[1;32m    455\u001b[0m     file_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_file_format,\n\u001b[1;32m    456\u001b[0m )\n\u001b[1;32m    458\u001b[0m \u001b[39m# Parse and decode\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_and_decode\u001b[39m(ex: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m TreeDict[Tensor]:\n\u001b[1;32m    460\u001b[0m   \u001b[39m# TODO(pierrot): `parse_example` uses\u001b[39;00m\n\u001b[1;32m    461\u001b[0m   \u001b[39m# `tf.io.parse_single_example`. It might be faster to use `parse_example`,\u001b[39;00m\n\u001b[1;32m    462\u001b[0m   \u001b[39m# after batching.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m   \u001b[39m# https://www.tensorflow.org/api_docs/python/tf/io/parse_example\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/reader.py:255\u001b[0m, in \u001b[0;36m_read_files\u001b[0;34m(file_instructions, read_config, shuffle_files, disable_shuffling, file_format)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m disable_shuffling:\n\u001b[1;32m    248\u001b[0m   _verify_read_config_for_ordered_dataset(\n\u001b[1;32m    249\u001b[0m       read_config,\n\u001b[1;32m    250\u001b[0m       interleave_cycle_length\u001b[39m=\u001b[39mcycle_length,\n\u001b[1;32m    251\u001b[0m       shuffle_files\u001b[39m=\u001b[39mshuffle_files,\n\u001b[1;32m    252\u001b[0m   )\n\u001b[0;32m--> 255\u001b[0m instruction_ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensor_slices(tensor_inputs)\n\u001b[1;32m    257\u001b[0m \u001b[39m# On distributed environments, we can shard per-file if a\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# `tf.distribute.InputContext` object is provided (e.g. from\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# `experimental_distribute_datasets_from_function`)\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m read_config\u001b[39m.\u001b[39minput_context:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:830\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[39m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 830\u001b[0m \u001b[39mreturn\u001b[39;00m from_tensor_slices_op\u001b[39m.\u001b[39;49m_from_tensor_slices(tensors, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_tensor_slices\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[39mreturn\u001b[39;00m _TensorSliceDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, element, is_files\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39;49mnormalize_element(element)\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:133\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m         dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(spec, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m         normalized_components\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 133\u001b[0m             ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcomponent_\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m i, dtype\u001b[39m=\u001b[39;49mdtype))\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1642\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1633\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1634\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1635\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1639\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m   1641\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1642\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1644\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1645\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     47\u001b[0m   \u001b[39mdel\u001b[39;00m as_ref  \u001b[39m# Unused.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(value, dtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:268\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    173\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \n\u001b[1;32m    175\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    269\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:280\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    279\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 280\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    282\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    283\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:305\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    304\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    306\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "raw_train_set, raw_valid_set, raw_test_set = tfds.load(\n",
    "    name='imdb_reviews',\n",
    "    split=['train[:90%]', 'train[90%:]', 'test'],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "train_set = raw_test_set.shuffle(5000).batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_set = raw_valid_set.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_set = raw_test_set.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"/home/amitaharoni/.tfhub\"\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\n",
    "        \"https://tfhub.dev/google/universal-sentence-encoder/4\", \n",
    "        trainable=True, \n",
    "        dtype=tf.string, input_shape=[]\n",
    "    ),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "folder = Path() / 'data/04-pretrained-finetuning' / 'model'\n",
    "if folder.exists():\n",
    "    tf.keras.models.load_model(folder)\n",
    "else:\n",
    "    model.fit(train_set, validation_data=valid_set, epochs=10)\n",
    "    model.save(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random zip trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3, 4), ('a', 'b', 'c', 'd')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRICK: zip can be used to unzip\n",
    "a = [1, 2, 3, 4]\n",
    "b = ['a', 'b', 'c', 'd']\n",
    "\n",
    "# After `zip`, the number of elements in each list becomes the length of the result\n",
    "zipped_list = list(zip(a, b))\n",
    "# => [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]\n",
    "\n",
    "# Since we now have N lists, each containing 2 elements, the length of the result is 2\n",
    "list(zip(*zipped_list))\n",
    "# => [(1, 2, 3, 4), ('a', 'b', 'c', 'd')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMT - Neural Machine Translation (Encoder-Decoder networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    "path = tf.keras.utils.get_file('spa-eng.zip', origin=url, cache_dir='datasets', extract=True)\n",
    "text = (Path(path).with_name('spa-eng') / 'spa.txt').read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118964\n",
      "What time is it? => Qué hora es?\n",
      "I need to know how to do this. => Necesito saber cómo hacer esto.\n",
      "Please fill this bucket with water. => Por favor, llena este balde con agua.\n"
     ]
    }
   ],
   "source": [
    "text = text.replace('¡', '').replace('¿', '')\n",
    "pairs = [pair.split('\\t') for pair in text.splitlines()]\n",
    "np.random.shuffle(pairs)\n",
    "print(len(pairs))\n",
    "sentences_en, sentences_es = zip(*pairs)\n",
    "for i in range(3):\n",
    "    print(sentences_en[i], '=>', sentences_es[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "# All sentences in the dataset have a max of 50 words, so this standardize without losing information\n",
    "max_length = 50\n",
    "text_vec_layer_en = tf.keras.layers.TextVectorization(max_tokens=vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_es = tf.keras.layers.TextVectorization(max_tokens=vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_en.adapt(sentences_en)\n",
    "text_vec_layer_es.adapt([f'startofseq {s} endofseq' for s in sentences_es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 'is', 'he']\n",
      "['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(text_vec_layer_en.get_vocabulary()[:10])\n",
    "print(text_vec_layer_es.get_vocabulary()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint = 100_000\n",
    "# Tokenization and embedding will be part of the model\n",
    "x_train = tf.constant(sentences_en[:breakpoint])\n",
    "x_valid = tf.constant(sentences_en[breakpoint:])\n",
    "x_train_decoder = tf.constant([f'startofseq {s}' for s in sentences_es[:breakpoint]])\n",
    "x_valid_decoder = tf.constant([f'startofseq {s}' for s in sentences_es[breakpoint:]])\n",
    "\n",
    "# But we tokenize to sparse categories the labels (the model will have softmax)\n",
    "y_train = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[:breakpoint]])\n",
    "y_valid = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[breakpoint:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 25 140  12   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(50,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[151 195  90  52  57   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(50,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "encoder_input = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_input = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "\n",
    "encoder_tokens = text_vec_layer_en(encoder_input)\n",
    "decoder_tokens = text_vec_layer_es(decoder_input)\n",
    "\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_tokens)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_tokens)\n",
    "\n",
    "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
    "encoder_output, *encoder_states = encoder(encoder_embeddings)\n",
    "\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_output = decoder(decoder_embeddings, initial_state=encoder_states)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "y_proba = output_layer(decoder_output)\n",
    "\n",
    "nmt_model = tf.keras.models.Model(inputs=[encoder_input, decoder_input], outputs=[y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 110s 31ms/step - loss: 3.2169 - accuracy: 0.3917 - val_loss: 2.5306 - val_accuracy: 0.4726\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 79s 25ms/step - loss: 2.2243 - accuracy: 0.5173 - val_loss: 2.0352 - val_accuracy: 0.5474\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 79s 25ms/step - loss: 1.8511 - accuracy: 0.5765 - val_loss: 1.8009 - val_accuracy: 0.5829\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 80s 26ms/step - loss: 1.6425 - accuracy: 0.6126 - val_loss: 1.6639 - val_accuracy: 0.6072\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 79s 25ms/step - loss: 1.5086 - accuracy: 0.6374 - val_loss: 1.5832 - val_accuracy: 0.6229\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 79s 25ms/step - loss: 1.4155 - accuracy: 0.6549 - val_loss: 1.5291 - val_accuracy: 0.6346\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 79s 25ms/step - loss: 1.3451 - accuracy: 0.6680 - val_loss: 1.4915 - val_accuracy: 0.6416\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 80s 26ms/step - loss: 1.2905 - accuracy: 0.6789 - val_loss: 1.4701 - val_accuracy: 0.6458\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 80s 25ms/step - loss: 1.2432 - accuracy: 0.6877 - val_loss: 1.4491 - val_accuracy: 0.6500\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 80s 26ms/step - loss: 1.2045 - accuracy: 0.6952 - val_loss: 1.4427 - val_accuracy: 0.6525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed8faee190>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmt_model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "nmt_model.fit(\n",
    "    (x_train, x_train_decoder), y_train, \n",
    "    epochs=10, \n",
    "    validation_data=((x_valid, x_valid_decoder), y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(en_input):\n",
    "    es_output = ''\n",
    "    en_input = tf.constant([en_input])\n",
    "    for token_index in range(max_length):\n",
    "        es_input = tf.constant([f'startofseq {es_output}'])\n",
    "        # The shape of predict() ~ [1, 50, 1000]\n",
    "        # We are interested in the most recently predicted token, i.e. at token_index\n",
    "        y_proba = nmt_model.predict([en_input, es_input], verbose=False)[0, token_index]\n",
    "        next_token = y_proba.argmax()\n",
    "        next_word = text_vec_layer_es.get_vocabulary()[next_token]\n",
    "        if next_word == 'endofseq':\n",
    "            break\n",
    "        es_output = f'{es_output} {next_word}'\n",
    "    return es_output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[90,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = nmt_model.predict([tf.constant(['how are you?']), tf.constant(['startofseq'])])\n",
    "next_token = y_proba.argmax(axis=-1)\n",
    "# text_vec_layer_es.get_vocabulary()[next_token]\n",
    "next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me voy a la cama\n",
      "me gusta el fútbol\n",
      "me gusta ir a [UNK] a las seis y media\n"
     ]
    }
   ],
   "source": [
    "print(translate('I am going to bed'))\n",
    "print(translate('I like soccer'))\n",
    "print(translate('I like soccer and going to the beach'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "encoder_input = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_input = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "\n",
    "encoder_tokens = text_vec_layer_en(encoder_input)\n",
    "decoder_tokens = text_vec_layer_es(decoder_input)\n",
    "\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_tokens)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_tokens)\n",
    "\n",
    "# Note the decrease in number of units to 256, as the final output is actually 512\n",
    "encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_state=True))\n",
    "encoder_output, *encoder_states = encoder(encoder_embeddings)\n",
    "encoder_states = [\n",
    "    tf.concat(encoder_states[::2], axis=-1),  # short-term state of sub-RNNs (0 & 2)\n",
    "    tf.concat(encoder_states[1::2], axis=-1)  # long-term state of sub-RNNs (1 & 3)\n",
    "]\n",
    "\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_output = decoder(decoder_embeddings, initial_state=encoder_states)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "y_proba = output_layer(decoder_output)\n",
    "\n",
    "nmt_model = tf.keras.models.Model(inputs=[encoder_input, decoder_input], outputs=[y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 130s 38ms/step - loss: 2.7593 - accuracy: 0.4518 - val_loss: 1.9807 - val_accuracy: 0.5519\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 98s 31ms/step - loss: 1.6770 - accuracy: 0.6057 - val_loss: 1.5347 - val_accuracy: 0.6333\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 99s 32ms/step - loss: 1.3301 - accuracy: 0.6703 - val_loss: 1.3815 - val_accuracy: 0.6632\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 1.1352 - accuracy: 0.7091 - val_loss: 1.3046 - val_accuracy: 0.6803\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 95s 31ms/step - loss: 0.9947 - accuracy: 0.7371 - val_loss: 1.2832 - val_accuracy: 0.6838\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 0.8795 - accuracy: 0.7613 - val_loss: 1.2758 - val_accuracy: 0.6867\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 97s 31ms/step - loss: 0.7822 - accuracy: 0.7832 - val_loss: 1.2894 - val_accuracy: 0.6880\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 0.6965 - accuracy: 0.8033 - val_loss: 1.3151 - val_accuracy: 0.6862\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 97s 31ms/step - loss: 0.6221 - accuracy: 0.8210 - val_loss: 1.3558 - val_accuracy: 0.6839\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 0.5580 - accuracy: 0.8371 - val_loss: 1.3953 - val_accuracy: 0.6828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec25ecf510>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmt_model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "nmt_model.fit(\n",
    "    (x_train, x_train_decoder), y_train, \n",
    "    epochs=10, \n",
    "    validation_data=((x_valid, x_valid_decoder), y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me voy a la cama\n",
      "me gusta el fútbol\n",
      "me gusta el fútbol y a la playa\n"
     ]
    }
   ],
   "source": [
    "print(translate('I am going to bed'))\n",
    "print(translate('I like soccer'))\n",
    "print(translate('I like soccer and going to the beach'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a él le gusta leer libros\n"
     ]
    }
   ],
   "source": [
    "print(translate('He likes reading books'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND: He often sits for many hours reading books.\n",
      "FOUND: Reading books is interesting.\n",
      "FOUND: I spent hours reading books.\n",
      "FOUND: Reading books will make you smarter.\n",
      "FOUND: Tom enjoys reading books in French.\n",
      "FOUND: He devoted himself to reading books.\n",
      "FOUND: I prefer reading books to watching television.\n",
      "FOUND: I love reading books.\n",
      "FOUND: I prefer reading books to watching television.\n",
      "FOUND: Reading books is very interesting.\n",
      "FOUND: I love reading books.\n",
      "FOUND: I prefer reading books to watching television.\n",
      "FOUND: We enjoy reading books.\n",
      "FOUND: I like reading books.\n"
     ]
    }
   ],
   "source": [
    "found = False\n",
    "for x in sentences_en:\n",
    "    if 'reading books' in x.lower():\n",
    "        print(f'FOUND: {x}')\n",
    "        found = True\n",
    "if not found:\n",
    "    print('Did not find it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(input, beam_width=3):\n",
    "    # We add another column which contains 0 for unfinished sentences and 1 for finished\n",
    "    proba_columns = text_vec_layer_es.vocabulary_size() + 1\n",
    "    # Compute indices to make it easier to move from a flattened array back to a matrix\n",
    "    x, y = np.indices((beam_width, proba_columns))\n",
    "    unflatten = tf.reshape(tf.stack([x, y], axis=-1), shape=(-1, 2))\n",
    "\n",
    "    en_sentences = tf.constant([input] * beam_width)\n",
    "    es_prefix = tf.constant(['startofseq '] * beam_width)\n",
    "    finished = tf.Variable([[0.]] * beam_width, dtype=tf.float32, shape=[beam_width, 1])\n",
    "    \n",
    "    # First words\n",
    "    vocab_probas = nmt_model.predict((tf.constant([input]), tf.constant(['startofseq'])), verbose=False)[0, 0, :]\n",
    "    top_k = tf.math.top_k(vocab_probas, k=beam_width)\n",
    "    es_sentences = tf.Variable([text_vec_layer_es.get_vocabulary()[x] for x in top_k.indices], dtype=tf.string)\n",
    "    # Use log probabilities to avoid numerical problems with long multiplications. \n",
    "    # So instead of P1 * P2, we do log(P1) + log(P2)\n",
    "    sentence_probas = tf.constant(tf.math.log(top_k.values), dtype=tf.float32, shape=[beam_width, 1])\n",
    "\n",
    "    for token_index in range(1, max_length):\n",
    "        curr_sentences = tf.constant(es_sentences)\n",
    "        # predict ~ (beam_width, 50, 1000)\n",
    "        # vocab_proba ~ (beam_width, 1000)\n",
    "        vocab_probas = nmt_model.predict((en_sentences, es_prefix + curr_sentences), verbose=False)[:, token_index]\n",
    "        # Concatenating the finish flag\n",
    "        # vocab_proba ~ (beam_width, 1001)\n",
    "        vocab_probas = tf.concat([vocab_probas, finished], axis=-1)\n",
    "        # flat_next_word_probas ~ (beam_width * 1001) \n",
    "        flat_next_word_probas = tf.reshape(sentence_probas + tf.math.log(vocab_probas), shape=[-1])\n",
    "        sentence_probas, flat_next_tokens = tf.math.top_k(flat_next_word_probas, k=beam_width)\n",
    "        sentence_probas = tf.reshape(sentence_probas, shape=[beam_width, 1])\n",
    "        for idx, flat_token in enumerate(flat_next_tokens):\n",
    "            chosen_sentence_idx, chosen_token = unflatten[flat_token]\n",
    "            if not finished[chosen_sentence_idx]:\n",
    "                word = text_vec_layer_es.get_vocabulary()[chosen_token]\n",
    "                if word == 'endofseq':\n",
    "                    finished[chosen_sentence_idx].assign(1)\n",
    "                else:\n",
    "                    es_sentences[idx].assign(curr_sentences[chosen_sentence_idx] + ' ' + word)\n",
    "\n",
    "        if np.all(finished):\n",
    "            break\n",
    "    print(es_sentences.numpy())\n",
    "    best_sentence = sentence_probas.numpy().argmax()\n",
    "    return es_sentences[best_sentence].numpy().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'me gusta mi coche' b'me gusta mi carro' b'me gusta mi auto']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'me gusta mi coche'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search('I like my car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'hello hi', b'world bye'], dtype=object)>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(['hello', 'world']) + tf.constant([' hi', ' bye'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_book(sentence_en, beam_width, verbose=False):\n",
    "    X = np.array([sentence_en])  # encoder input\n",
    "    X_dec = np.array([\"startofseq\"])  # decoder input\n",
    "    y_proba = nmt_model.predict((X, X_dec), verbose=False)[0, 0]  # first token's probas\n",
    "    top_k = tf.math.top_k(y_proba, k=beam_width)\n",
    "    top_translations = [  # list of best (log_proba, translation)\n",
    "        (np.log(word_proba), text_vec_layer_es.get_vocabulary()[word_id])\n",
    "        for word_proba, word_id in zip(top_k.values, top_k.indices)\n",
    "    ]\n",
    "    \n",
    "    # extra code – displays the top first words in verbose mode\n",
    "    if verbose:\n",
    "        print(\"Top first words:\", top_translations)\n",
    "\n",
    "    for idx in range(1, max_length):\n",
    "        candidates = []\n",
    "        for log_proba, translation in top_translations:\n",
    "            if translation.endswith(\"endofseq\"):\n",
    "                candidates.append((log_proba, translation))\n",
    "                continue  # translation is finished, so don't try to extend it\n",
    "            X = np.array([sentence_en])  # encoder input\n",
    "            X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
    "            y_proba = nmt_model.predict((X, X_dec), verbose=False)[0, idx]  # last token's proba\n",
    "            for word_id, word_proba in enumerate(y_proba):\n",
    "                word = text_vec_layer_es.get_vocabulary()[word_id]\n",
    "                candidates.append((log_proba + np.log(word_proba),\n",
    "                                   f\"{translation} {word}\"))\n",
    "        top_translations = sorted(candidates, reverse=True)[:beam_width]\n",
    "\n",
    "        # extra code – displays the top translation so far in verbose mode\n",
    "        if verbose:\n",
    "            print(\"Top translations so far:\", top_translations)\n",
    "\n",
    "        if all([tr.endswith(\"endofseq\") for _, tr in top_translations]):\n",
    "            return top_translations[0][1].replace(\"endofseq\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top first words: [(-0.0039384337, 'me'), (-6.8156004, 'mi'), (-7.1107097, 'a')]\n",
      "Top translations so far: [(-0.005191154, 'me gusta'), (-6.997386, 'me [UNK]'), (-7.1742353, 'a mi')]\n",
      "Top translations so far: [(-0.03985434, 'me gusta mi'), (-3.4733727, 'me gusta el'), (-6.407665, 'me gusta ese')]\n",
      "Top translations so far: [(-0.62566996, 'me gusta mi coche'), (-1.7064795, 'me gusta mi carro'), (-1.795997, 'me gusta mi auto')]\n",
      "Top translations so far: [(-0.62573564, 'me gusta mi coche endofseq'), (-1.706535, 'me gusta mi carro endofseq'), (-1.7960483, 'me gusta mi auto endofseq')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta mi coche'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search_book('I like my car', 3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "encoder_input = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_input = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "\n",
    "encoder_tokens = text_vec_layer_en(encoder_input)\n",
    "decoder_tokens = text_vec_layer_es(decoder_input)\n",
    "\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_tokens)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_tokens)\n",
    "\n",
    "# Note that we now return sequences\n",
    "encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_state=True, return_sequences=True))\n",
    "encoder_output, *encoder_states = encoder(encoder_embeddings)\n",
    "encoder_states = [\n",
    "    tf.concat(encoder_states[::2], axis=-1),  # short-term state of sub-RNNs (0 & 2)\n",
    "    tf.concat(encoder_states[1::2], axis=-1)  # long-term state of sub-RNNs (1 & 3)\n",
    "]\n",
    "\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_output = decoder(decoder_embeddings, initial_state=encoder_states)\n",
    "\n",
    "# Luong attention\n",
    "# To send the full decoder's states (hidden + long term) we would need to write a custom layer.\n",
    "# Instead, we simply send the outputs (= hidden states), which in practice works well.\n",
    "attention_layer = tf.keras.layers.Attention()\n",
    "attention_output = attention_layer([decoder_output, encoder_output])\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "y_proba = output_layer(attention_output)\n",
    "\n",
    "nmt_model = tf.keras.models.Model(inputs=[encoder_input, decoder_input], outputs=[y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 124s 36ms/step - loss: 3.1142 - accuracy: 0.4145 - val_loss: 2.0253 - val_accuracy: 0.5618\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 100s 32ms/step - loss: 1.7144 - accuracy: 0.6131 - val_loss: 1.5786 - val_accuracy: 0.6369\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 98s 31ms/step - loss: 1.4170 - accuracy: 0.6653 - val_loss: 1.4378 - val_accuracy: 0.6635\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 99s 32ms/step - loss: 1.2636 - accuracy: 0.6935 - val_loss: 1.3641 - val_accuracy: 0.6789\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 98s 31ms/step - loss: 1.1533 - accuracy: 0.7149 - val_loss: 1.3341 - val_accuracy: 0.6847\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 97s 31ms/step - loss: 1.0663 - accuracy: 0.7315 - val_loss: 1.3125 - val_accuracy: 0.6900\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 99s 32ms/step - loss: 0.9911 - accuracy: 0.7467 - val_loss: 1.3135 - val_accuracy: 0.6925\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 100s 32ms/step - loss: 0.9263 - accuracy: 0.7600 - val_loss: 1.3184 - val_accuracy: 0.6929\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 100s 32ms/step - loss: 0.8676 - accuracy: 0.7725 - val_loss: 1.3298 - val_accuracy: 0.6934\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 99s 32ms/step - loss: 0.8164 - accuracy: 0.7831 - val_loss: 1.3561 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec1a5b6d90>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmt_model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "nmt_model.fit(\n",
    "    (x_train, x_train_decoder), y_train, \n",
    "    epochs=10, \n",
    "    validation_data=((x_valid, x_valid_decoder), y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me voy a la cama\n",
      "me gusta fútbol\n",
      "me gusta el fútbol y a a la playa\n"
     ]
    }
   ],
   "source": [
    "print(translate('I am going to bed'))\n",
    "print(translate('I like soccer'))\n",
    "print(translate('I like soccer and going to the beach'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'me voy a la cama' b'voy a la cama' b'me [UNK]']\n",
      "b'me voy a la cama'\n",
      "[b'me gusta f\\xc3\\xbatbol' b'me gusta el f\\xc3\\xbatbol'\n",
      " b'me gusta jugar el f\\xc3\\xbatbol']\n",
      "b'me gusta f\\xc3\\xbatbol'\n",
      "[b'me gusta el f\\xc3\\xbatbol y a a la playa'\n",
      " b'me gusta el f\\xc3\\xbatbol y a la playa'\n",
      " b'me gusta el f\\xc3\\xbatbol y a ir a la playa']\n",
      "b'me gusta el f\\xc3\\xbatbol y a a la playa'\n"
     ]
    }
   ],
   "source": [
    "print(beam_search('I am going to bed'))\n",
    "print(beam_search('I like soccer'))\n",
    "print(beam_search('I like soccer and going to the beach'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encodings: Trainable embeddings approach (not used in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50\n",
    "embed_size = 128\n",
    "\n",
    "pos_embed_layer = tf.keras.layers.Embedding(input_dim=max_length, output_dim=embed_size)\n",
    "# This gets the sequence length of the encoder's input during training or inference\n",
    "batch_max_len_enc = tf.shape(encoder_embeddings)[1]\n",
    "# Embeds the range 0..seqlen and adds it to the output of the encoder_embeddings\n",
    "encoder_in = encoder_embeddings + pos_embed_layer(tf.range(batch_max_len_enc))\n",
    "\n",
    "# Remember the decoder's sequence length can be different than the encoder's\n",
    "batch_max_len_dec = tf.shape(decoder_embeddings)[1]\n",
    "# We add the same positional encoding representation to both encoder's and decoder's embeddings\n",
    "decoder_in = decoder_embeddings + pos_embed_layer(tf.range(batch_max_len_dec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encodings: fixed positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedPositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_length, embed_size, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        assert embed_size % 2 == 0, \"embed_size must be even\"\n",
    "        p, i = np.meshgrid(np.arange(max_length), 2 * np.arange(embed_size // 2))\n",
    "        # Shape of a tensor (1, max_length, embed_size) that will be broadcasted across batches\n",
    "        pos_emb = np.empty((1, max_length, embed_size))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10_000 ** (i / embed_size)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10_000 ** (i / embed_size)).T\n",
    "        self.pos_encoding = tf.constant(pos_emb.astype(self.dtype))\n",
    "        self.supports_masking = True\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        batch_max_len = tf.shape(inputs)[1]\n",
    "        return inputs + self.pos_encoding[:, :batch_max_len]\n",
    "\n",
    "pos_embed_layer = FixedPositionalEncoding(max_length, embed_size)\n",
    "encoder_in = pos_embed_layer(encoder_embeddings)\n",
    "decoder_in = pos_embed_layer(decoder_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]]\n",
      "[[10 10 10 10 10]\n",
      " [11 11 11 11 11]\n",
      " [12 12 12 12 12]\n",
      " [13 13 13 13 13]\n",
      " [14 14 14 14 14]\n",
      " [15 15 15 15 15]]\n",
      "[10  0]\n",
      "[10  1]\n",
      "[11  0]\n"
     ]
    }
   ],
   "source": [
    "x, y = np.meshgrid(np.arange(5), np.arange(10,16))\n",
    "print(x)\n",
    "print(y)\n",
    "z = np.stack([y, x], axis=2)\n",
    "print(z[0, 0])\n",
    "print(z[0, 1])\n",
    "print(z[1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization_3 (TextVect  (None, 50)          0           ['input_28[0][0]']               \n",
      " orization)                                                                                       \n",
      "                                                                                                  \n",
      " text_vectorization_2 (TextVect  (None, 50)          0           ['input_27[0][0]']               \n",
      " orization)                                                                                       \n",
      "                                                                                                  \n",
      " embedding_67 (Embedding)       (None, 50, 128)      128000      ['text_vectorization_3[13][0]']  \n",
      "                                                                                                  \n",
      " tf.math.not_equal_4 (TFOpLambd  (None, 50)          0           ['text_vectorization_2[13][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " embedding_66 (Embedding)       (None, 50, 128)      128000      ['text_vectorization_2[13][0]']  \n",
      "                                                                                                  \n",
      " fixed_positional_encoding_7 (F  (None, 50, 128)     0           ['embedding_66[0][0]',           \n",
      " ixedPositionalEncoding)                                          'embedding_67[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, 1, 50)       0           ['tf.math.not_equal_4[0][0]']    \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 50, 128)     527488      ['fixed_positional_encoding_7[0][\n",
      " HeadAttention)                                                  0]',                             \n",
      "                                                                  'tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'fixed_positional_encoding_7[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_52 (Add)                   (None, 50, 128)      0           ['multi_head_attention_20[0][0]',\n",
      "                                                                  'fixed_positional_encoding_7[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 50, 128)     256         ['add_52[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 50, 128)      16512       ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 50, 128)      16512       ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 50, 128)      0           ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " add_53 (Add)                   (None, 50, 128)      0           ['dropout_14[0][0]',             \n",
      "                                                                  'layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 50, 128)     256         ['add_53[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_2 (TFOpLamb  (3,)                0           ['fixed_positional_encoding_7[1][\n",
      " da)                                                             0]']                             \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 50, 128)     527488      ['layer_normalization_34[0][0]', \n",
      " HeadAttention)                                                   'tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  ()                  0           ['tf.compat.v1.shape_2[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " add_54 (Add)                   (None, 50, 128)      0           ['multi_head_attention_21[0][0]',\n",
      "                                                                  'layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.not_equal_5 (TFOpLambd  (None, 50)          0           ['text_vectorization_3[13][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.ones_2 (TFOpLambda)         (50, 50)             0           ['tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 50, 128)     256         ['add_54[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8 (Sl  (None, 1, 50)       0           ['tf.math.not_equal_5[0][0]']    \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.linalg.band_part_2 (TFOpLam  (50, 50)            0           ['tf.ones_2[0][0]']              \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 50, 128)      16512       ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.logical_and_4 (TFOpLam  (None, 50, 50)      0           ['tf.__operators__.getitem_8[0][0\n",
      " bda)                                                            ]',                              \n",
      "                                                                  'tf.linalg.band_part_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 50, 128)      16512       ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 50, 128)     527488      ['fixed_positional_encoding_7[1][\n",
      " HeadAttention)                                                  0]',                             \n",
      "                                                                  'tf.math.logical_and_4[0][0]',  \n",
      "                                                                  'fixed_positional_encoding_7[1][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 50, 128)      0           ['dense_39[0][0]']               \n",
      "                                                                                                  \n",
      " add_56 (Add)                   (None, 50, 128)      0           ['multi_head_attention_22[0][0]',\n",
      "                                                                  'fixed_positional_encoding_7[1][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_55 (Add)                   (None, 50, 128)      0           ['dropout_15[0][0]',             \n",
      "                                                                  'layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 50, 128)     256         ['add_56[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 50, 128)     256         ['add_55[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 50, 128)     527488      ['layer_normalization_37[0][0]', \n",
      " HeadAttention)                                                   'tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 50, 128)      0           ['multi_head_attention_23[0][0]',\n",
      "                                                                  'layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 50, 128)     256         ['add_57[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 50, 128)      16512       ['layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 50, 128)      16512       ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " add_58 (Add)                   (None, 50, 128)      0           ['dense_41[0][0]',               \n",
      "                                                                  'layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 50, 128)     256         ['add_58[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.logical_and_5 (TFOpLam  (None, 50, 50)      0           ['tf.__operators__.getitem_8[0][0\n",
      " bda)                                                            ]',                              \n",
      "                                                                  'tf.linalg.band_part_2[0][0]']  \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 50, 128)     527488      ['layer_normalization_39[0][0]', \n",
      " HeadAttention)                                                   'tf.math.logical_and_5[0][0]',  \n",
      "                                                                  'layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " add_59 (Add)                   (None, 50, 128)      0           ['multi_head_attention_24[0][0]',\n",
      "                                                                  'layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 50, 128)     256         ['add_59[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 50, 128)     527488      ['layer_normalization_40[0][0]', \n",
      " HeadAttention)                                                   'tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 50, 128)      0           ['multi_head_attention_25[0][0]',\n",
      "                                                                  'layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 50, 128)     256         ['add_60[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 50, 128)      16512       ['layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 50, 128)      16512       ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 50, 128)      0           ['dense_43[0][0]',               \n",
      "                                                                  'layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 50, 128)     256         ['add_61[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 50, 1000)     129000      ['layer_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,684,584\n",
      "Trainable params: 3,684,584\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_length = 50\n",
    "embed_size = 128\n",
    "vocab_size = 1000\n",
    "\n",
    "# = The inputs\n",
    "\n",
    "encoder_input = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_input = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "\n",
    "encoder_tokens = text_vec_layer_en(encoder_input)\n",
    "decoder_tokens = text_vec_layer_es(decoder_input)\n",
    "\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_tokens)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_tokens)\n",
    "\n",
    "pos_embed_layer = FixedPositionalEncoding(max_length, embed_size)\n",
    "encoder_in = pos_embed_layer(encoder_embeddings)\n",
    "decoder_in = pos_embed_layer(decoder_embeddings)\n",
    "\n",
    "# = The Encoder\n",
    "\n",
    "# instead of 6\n",
    "N = 2 \n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "# For the first dense layer in each feedforward block\n",
    "# In the paper this increased dimensionality of the embeddings by 4x\n",
    "n_units = 128 \n",
    "# This might not be needed anymore in new versions of Tensorflow\n",
    "# The last bit transforms the mask from (batch size, encoder sequence length) to\n",
    "# (batch size, 1, encoder sequence length)\n",
    "encoder_pad_mask = tf.math.not_equal(encoder_tokens, 0)[:, tf.newaxis]\n",
    "Z = encoder_in\n",
    "for _ in range(N):\n",
    "    skip = Z\n",
    "    # == Multi-head self-attention\n",
    "    attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, \n",
    "        key_dim=embed_size, \n",
    "        dropout=dropout_rate\n",
    "    )\n",
    "    # Since `key` is not provided, uses the value\n",
    "    # attention_mask is of shape (batch size, query sequence length, keys sequence length)\n",
    "    # The provided mask is of shape (batch size, 1, keys sequence length), so is broadcasted.\n",
    "    # However, the layer computes output for all query tokens, which in this case are the same as the keys. \n",
    "    # I.e. the output will contain the results of padded encoder tokens, which should be ignored...\n",
    "    Z = attn_layer(Z, value=Z, attention_mask=encoder_pad_mask)\n",
    "    # ... the Add layer in Keras propagates the mask of the layers. If any mask cell is False, the \n",
    "    # aggregate mask is considered False. This solves the aforementioned issue.\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "    skip = Z\n",
    "    # == Feed-forward\n",
    "    Z = tf.keras.layers.Dense(n_units, activation='relu')(Z)\n",
    "    Z = tf.keras.layers.Dense(embed_size)(Z)\n",
    "    Z = tf.keras.layers.Dropout(dropout_rate)(Z)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "\n",
    "encoder_output = Z\n",
    "\n",
    "# = The Decoder\n",
    "\n",
    "# The sequence length of the decoder\n",
    "batch_max_len_dec = tf.shape(decoder_in)[1]\n",
    "\n",
    "decoder_pad_mask = tf.math.not_equal(decoder_tokens, 0)[:, tf.newaxis]\n",
    "# The causal mask shape is (decoder seqlen, decoder seqlen).\n",
    "# It will be broadcasted across all batches to (batch size, decoder seqlen, decoder seqlen)\n",
    "causal_mask = tf.linalg.band_part(\n",
    "    tf.ones((batch_max_len_dec, batch_max_len_dec), tf.bool), \n",
    "    # Take all values below the diagonal\n",
    "    num_lower=-1,\n",
    "    # Take none of the values above the diagonal\n",
    "    num_upper=0\n",
    ")\n",
    "\n",
    "Z = decoder_in\n",
    "for _ in range(N):\n",
    "    skip = Z\n",
    "    # == Masked multi-head self-attention\n",
    "    attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, \n",
    "        key_dim=embed_size, \n",
    "        dropout=dropout_rate\n",
    "    )\n",
    "    Z = attn_layer(Z, value=Z, attention_mask=decoder_pad_mask & causal_mask)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "    skip = Z\n",
    "    # == Multi-head cross-attention\n",
    "    attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=embed_size,\n",
    "        dropout=dropout_rate\n",
    "    )\n",
    "    # Note we're using encoder_pad_mask, as this is the value space it returns\n",
    "    Z = attn_layer(Z, value=encoder_output, attention_mask=encoder_pad_mask)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "    skip = Z\n",
    "    # == Feed-forward\n",
    "    Z = tf.keras.layers.Dense(n_units, activation='relu')(Z)\n",
    "    Z = tf.keras.layers.Dense(embed_size)(Z)\n",
    "    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n",
    "\n",
    "y_proba = tf.keras.layers.Dense(vocab_size, activation='softmax')(Z)\n",
    "\n",
    "transformer_model = tf.keras.models.Model(inputs=[encoder_input, decoder_input], outputs=[y_proba])\n",
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 233s 67ms/step - loss: 2.7945 - sparse_categorical_accuracy: 0.4486 - val_loss: 1.9859 - val_sparse_categorical_accuracy: 0.5700\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 224s 72ms/step - loss: 1.7874 - sparse_categorical_accuracy: 0.5971 - val_loss: 1.5992 - val_sparse_categorical_accuracy: 0.6323\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 222s 71ms/step - loss: 1.5594 - sparse_categorical_accuracy: 0.6368 - val_loss: 1.4577 - val_sparse_categorical_accuracy: 0.6600\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 223s 71ms/step - loss: 1.4487 - sparse_categorical_accuracy: 0.6558 - val_loss: 1.3936 - val_sparse_categorical_accuracy: 0.6695\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 223s 71ms/step - loss: 1.3762 - sparse_categorical_accuracy: 0.6682 - val_loss: 1.3478 - val_sparse_categorical_accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 220s 70ms/step - loss: 1.3262 - sparse_categorical_accuracy: 0.6764 - val_loss: 1.3021 - val_sparse_categorical_accuracy: 0.6873\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 218s 70ms/step - loss: 1.2845 - sparse_categorical_accuracy: 0.6840 - val_loss: 1.2639 - val_sparse_categorical_accuracy: 0.6945\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 222s 71ms/step - loss: 1.2506 - sparse_categorical_accuracy: 0.6900 - val_loss: 1.2398 - val_sparse_categorical_accuracy: 0.6997\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 224s 72ms/step - loss: 1.2202 - sparse_categorical_accuracy: 0.6963 - val_loss: 1.2223 - val_sparse_categorical_accuracy: 0.7022\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 221s 71ms/step - loss: 1.1948 - sparse_categorical_accuracy: 0.7006 - val_loss: 1.2021 - val_sparse_categorical_accuracy: 0.7058\n"
     ]
    }
   ],
   "source": [
    "transformer_model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Nadam(),\n",
    "    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    ")\n",
    "hist = transformer_model.fit((x_train, x_train_decoder), y_train, epochs=10, validation_data=((x_valid, x_valid_decoder), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voy a la cama\n",
      "me gusta el fútbol\n",
      "me gusta el fútbol y la playa\n"
     ]
    }
   ],
   "source": [
    "def translate(en_input):\n",
    "    es_output = ''\n",
    "    en_input = tf.constant([en_input])\n",
    "    for token_index in range(max_length):\n",
    "        es_input = tf.constant([f'startofseq {es_output}'])\n",
    "        # The shape of predict() ~ [1, 50, 1000]\n",
    "        # We are interested in the most recently predicted token, i.e. at token_index\n",
    "        y_proba = transformer_model.predict([en_input, es_input], verbose=False)[0, token_index]\n",
    "        next_token = y_proba.argmax()\n",
    "        next_word = text_vec_layer_es.get_vocabulary()[next_token]\n",
    "        if next_word == 'endofseq':\n",
    "            break\n",
    "        es_output = f'{es_output} {next_word}'\n",
    "    return es_output.strip()\n",
    "\n",
    "print(translate('I am going to bed'))\n",
    "print(translate('I like soccer'))\n",
    "print(translate('I like soccer and going to the beach'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81928fb7d1794f16877e9bbf8e6d581a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207d36e407104183b4f830f9c701e3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb0d50424fb44878cf1b1dc418fd981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0bbef1cb3d449fafd45b24002e30a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998143315315247}]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# sentiment-analysis is the task. Since no model is specified, it downloads the default one.\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "result = classifier('The actors were very convincing')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9769665598869324}]\n",
      "[{'label': 'POSITIVE', 'score': 0.987899124622345}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9868885278701782}]\n",
      "[{'label': 'POSITIVE', 'score': 0.8568997979164124}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9706069231033325}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier('I am from USA'))\n",
    "print(classifier('I am from Israel'))\n",
    "print(classifier('I am from Austria'))\n",
    "print(classifier('I am from Germany'))\n",
    "print(classifier('I am from Iraq'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9a335dda984e108037e1228a4d21bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cefff0d0a1342c79f59b30b13923aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8454d0be310b4c2abf39e7f276bb3dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/58.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b6e532103145138587537804171136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe325cd55e7b4d55b8e97f9630597764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95200876b2e47faaec07bc95495cd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'contradiction', 'score': 0.9790192246437073}]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we specify the task & model.\n",
    "model_name = 'huggingface/distilbert-base-uncased-finetuned-mnli'\n",
    "classifier_mnli = pipeline('text-classification', model=model_name)\n",
    "classifier_mnli('She loves me. [SEP] She loves me not.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
       "array([[ 101, 1045, 2066, 4715, 1012,  102, 2057, 2035, 2293, 4715,  999,\n",
       "         102,    0,    0,    0],\n",
       "       [ 101, 3533, 2973, 2005, 1037, 2200, 2146, 2051, 1012,  102, 3533,\n",
       "        2003, 2214, 1012,  102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "token_ids = tokenizer(['I like soccer. [SEP] We all love soccer!',\n",
    "    'Joe lived for a very long time. [SEP] Joe is old.'], \n",
    "    padding = True, return_tensors='tf'\n",
    ")\n",
    "\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[-2.1110213 ,  1.178814  ,  1.4085091 ],\n",
       "       [-0.01528974,  1.0974947 , -0.9926476 ]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(token_ids)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.01623192 0.43563944 0.54812866]\n",
      " [0.22628923 0.6885572  0.08515355]], shape=(2, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 1])>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas = tf.keras.activations.softmax(output.logits)\n",
    "print(y_probas)\n",
    "y_pred = tf.argmax(y_probas, axis=1)\n",
    "y_pred # 0 = contradiction, 1 = entailment, 2 = neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning of a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "array([[ 101, 3712, 2003, 2630,  102, 3712, 2003, 2417,  102],\n",
      "       [ 101, 1045, 2293, 2014,  102, 2016, 7459, 2033,  102]],\n",
      "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 34s 34s/step - loss: 1.5253 - accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1004 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "sentences = [('Sky is blue', 'Sky is red'), ('I love her', 'She loves me')]\n",
    "# Without the `data` call, it returns BatchEncoding class, which cannot be used to train the model\n",
    "# Calling `data` returns a dict\n",
    "x_train = tokenizer(sentences, padding=True, return_tensors='tf').data\n",
    "print(x_train)\n",
    "y_train = tf.constant([0, 2]) # Contradiction, Neutral\n",
    "# The model outputs logits, not probabilities - so our loss function needs to know that\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527488"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ixed_positional_encoding_4 (F  (None, 50, 128)     0           ['embedding_20[0][0]']           \n",
    "#  ixedPositionalEncoding)                                                                          \n",
    "                                                                                                  \n",
    "#  multi_head_attention_6 (MultiH  (None, 50, 128)     527488      ['fixed_positional_encoding_4[0][\n",
    "#  eadAttention)                                                   0]',                             \n",
    "#                                                                   'fixed_positional_encoding_4[0][\n",
    "\n",
    "# Got it!\n",
    "# We have 3 linear projections applied to the queries, values, and heads. \n",
    "# To adhere to num_heads=8, we take the tensor length on the final axis (embed_size=128) and multiply it by 8 => 128 * 8 = 1024. \n",
    "# So there is a normal Dense transformation from (32, 50, 128) => (32, 50, 1024) using a (128, 1024) matrix with 128*1024+1024 parameters.\n",
    "# This is done 3 times. Then, after the scaled attention, we have the reverse transformation from (32, 50, 1024) to (32, 50, 128).\n",
    "# This is done again using a normal Dense transformation using a (1024, 128) matrix with 1024*128+128\n",
    "(128 * (128 * 8) + (128 * 8)) * 3 + ((128 * 8) * 128 + 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "(4, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [9, 8, 7]\n",
    "])\n",
    "\n",
    "print(tensor.shape)\n",
    "tensor2 = tensor[:, tf.newaxis]\n",
    "print(tensor2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5) (1, 5)\n",
      "tf.Tensor([[ True False False False False]], shape=(1, 5), dtype=bool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5, 5])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_a = tf.constant([[1, 2, 0, 0, 0]])\n",
    "input_b = tf.constant([[1, 0, 0, 0, 0]])\n",
    "\n",
    "print(input_a.shape, input_b.shape)\n",
    "\n",
    "embeddings_layer_a = tf.keras.layers.Embedding(input_dim=3, output_dim=5, mask_zero=True)\n",
    "embeddings_a = embeddings_layer_a(input_a)\n",
    "\n",
    "embeddings_layer_b = tf.keras.layers.Embedding(input_dim=3, output_dim=5, mask_zero=True)\n",
    "embeddings_b = embeddings_layer_b(input_b)\n",
    "\n",
    "output = tf.keras.layers.Add()([embeddings_a, embeddings_b])\n",
    "print(output._keras_mask)\n",
    "\n",
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
