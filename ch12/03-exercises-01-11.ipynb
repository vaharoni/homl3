{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular deep learning libraries?\n",
    "\n",
    "> Library that allows running mathematical operations on the GPU, and supports various use-cases related to training and deploying deep learning models.\n",
    "> Other libraries are PyTorch and JAX."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
    "\n",
    "> Not really, but they are similar. Tensorflow runs operations on the GPU. Numpy is not able to do so.\n",
    "\n",
    "Book answer:\n",
    "> Although TensorFlow offers most of the functionalities provided by NumPy, it is not a drop-in replacement, for a few reasons. First, the names of the functions are not always the same (for example, tf.reduce_sum() versus np.sum()). Second, some functions do not behave in exactly the same way (for example, tf.transpose() creates a transposed copy of a tensor, while NumPy's T attribute creates a transposed view, without actually copying any data). Lastly, NumPy arrays are mutable, while TensorFlow tensors are not (but you can use a tf.Variable if you need a mutable object)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n",
    "\n",
    "> No, one returns a tensor and the other an ndarray.\n",
    "\n",
    "INCORRECT\n",
    "\n",
    "Book:\n",
    "> Both tf.range(10) and tf.constant(np.arange(10)) return a one-dimensional tensor containing the integers 0 to 9. However, the former uses 32-bit integers while the latter uses 64-bit integers. Indeed, TensorFlow defaults to 32 bits, while NumPy defaults to 64 bits."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:16:43.628919Z",
     "start_time": "2023-06-21T15:16:40.544498Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:16:59.253187Z",
     "start_time": "2023-06-21T15:16:59.241168Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
    "\n",
    "> Keras:\n",
    ">   Models\n",
    ">   Layers\n",
    ">   Loss functions\n",
    ">   Metrics\n",
    ">   Regularizers\n",
    ">   Optimizers\n",
    ">   Initalizers\n",
    ">   Constraints\n",
    ">\n",
    "> TF:\n",
    ">   tf.Variable\n",
    ">   tf.function\n",
    ">   ???\n",
    "\n",
    "Book:\n",
    "> Beyond regular tensors, TensorFlow offers several other data structures, including sparse tensors, tensor arrays, ragged tensors, queues, string tensors, and sets. The last two are actually represented as regular tensors, but TensorFlow provides special functions to manipulate them (in tf.strings and tf.sets)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. You can define a custom loss function by writing a function or by subclassing the tf.keras.losses.Loss class. When would you use each option?\n",
    "\n",
    "> Subclassing the Loss class is useful when we want to save hyperparams together with the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Similarly, you can define a custom metric in a function or as a subclass of tf.keras.metrics.Metric. When would you use each option?\n",
    "\n",
    "> Same\n",
    "\n",
    "FORGOT: stream metric also needs to be derived, not only for hyperparams\n",
    "\n",
    "Book:\n",
    "> Much like custom loss functions, most metrics can be defined as regular Python functions. But if you want your custom metric to support some hyperparameters (or any other state), then you should subclass the keras.metrics.Metric class. Moreover, if computing the metric over a whole epoch is not equivalent to computing the mean metric over all batches in that epoch (e.g., as for the precision and recall metrics), then you should subclass the keras.metrics.Metric class and implement the __init__(), update_state(), and result() methods to keep track of a running metric during each epoch. You should also implement the reset_states() method unless all it needs to do is reset all variables to 0.0. If you want the state to be saved along with the model, then you should implement the get_config() method as well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. When should you create a custom layer versus a custom model?\n",
    "\n",
    "> A custom layer is for a building block used in a model.\n",
    "> A custom model can be useful for exotic situations, e.g. when there are two outputs (auxiliary output) - adding another model-wise loss component."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8. What are some use cases that require writing your own custom training loop?\n",
    "\n",
    "> One use case is using different optimizers for different pathways of the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "9. Can custom Keras components contain arbitrary Python code, or must they be convertible to TF functions?\n",
    "\n",
    "> They can. But some python code means they won't become part of to the execution graph and will only be executed during tracing. This could either create unexpected results (e.g. using np.random.rand) or won't be as performant and require the python dependencies to be installed (if a function is wrapped with tf.py_function())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "10. What are the main rules to respect if you want a function to be convertible to a TF function?\n",
    "\n",
    "> Only use tf constructs for them to appear on the graph, as python code would only run during tracing\n",
    "> Creating stateful objects (tf.Variable, queue) should happen outside of the function (in reality - needs to happen only on the first call)\n",
    "> Source code must be available, i.e. won't work in REPL\n",
    "> Iterations must be over tf.range or tensor dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "11. When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n",
    "\n",
    "> How: Set dynamic=True when creating the model, or run_eagerly=True when calling compile().\n",
    "> Why: When for some reason I need non tf constructs to run as part of the model.\n",
    "> Effect: This would cause performance issues as they cannot be optimized"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
